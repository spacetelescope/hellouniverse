{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3c142db-3ee1-41b7-8396-03308661e308",
   "metadata": {},
   "source": [
    "# An AI-Powered Light Curve Similarity Search\n",
    "\n",
    "## Learning Goals\n",
    "\n",
    "In this notebook, we will build and train a Convolutional Neural Network (CNN) classifier on transforms of variable star light curves from [TESS-SPOC](https://archive.stsci.edu/hlsp/tess-spoc), then extract embedding vectors to build a light curve similarity search database. \n",
    "\n",
    "## Introduction\n",
    "\n",
    "Conventional light curve data searches are conducted based on metadata---stellar parameters like effective temperature or radius, light curve measurements like amplitude or photometric precision, etc. However, interesting classes of variables don't always fit nicely into these metadata boxes, making class members difficult to query without expensive light curve analyses. For example, eclipsing binary light curves can come from any type of star system, regardless of their stellar parameters. Queries for these types of targets must be done on the features of the light curves themselves.\n",
    "\n",
    "The enormous wealth of time series photometry from space missions like Kepler, K2, TESS, and soon Roman presents a major challenge to astrophysics investigations that must analyze light curves individually to identify science samples. Analyzing the ~24 million light curves from the first two years of TESS alone, without high performance or multicore computing, would take over nine months at a single second per light curve. Faster, more intelligent algorithms are necessary for bulk analysis in a reasonable timeframe. \n",
    "\n",
    "This notebook presents the end-to-end development of a light curve similarity search database powered by machine learning. In such a fast-searching vector database, users can choose a target or upload a light curve and quickly retrieve a desired number of “similar” targets, where similarity is determined against an extracted layer of a trained neural network called a \"feature embedding\" or \"embedding vector.\" For our light curves, we will use the MAST High Level Science Product [TESS-SPOC](https://archive.stsci.edu/hlsp/tess-spoc), which consists of full-framge image light curves from the Transiting Exoplanet Survey Satellite (TESS) processed by the Science Processing Operations Center (SPOC) pipeline. In its search for transiting exoplanets, TESS measures light curves for millions of stars, which are useful for identifying stellar astrophysical phenomena like rotation, flares, and binary eclipses.\n",
    "\n",
    "In the similarity search database, each light curve has an associated embedding vector, which consists of some number (in this case 64) floating point values. This means that the database is relatively small compared to the size of a full light curve database. To find light curves similar to a desired target, the target embedding vector is compared to all of the vectors in the database using the euclidean distance, which is also a fast and lightweight computation.\n",
    "\n",
    "To build the similarity search, we must do the following:\n",
    "1. Choose a training set\n",
    "2. Preprocess the training data\n",
    "3. Build a CNN classifier\n",
    "4. Train the CNN\n",
    "5. Evaluate the CNN performance\n",
    "6. Extract the embedding vectors and demonstrate a similarity search\n",
    "\n",
    "## Dependencies\n",
    "\n",
    "This notebook uses the following packages:\n",
    "- `numpy` for general numeric operations\n",
    "- `pandas` to contain data in DataFrames\n",
    "- `scipy` for its Fast Fourier Transform library\n",
    "- `matplotlib.pyplot` for plotting\n",
    "- `lightkurve` for interacting with light curve data\n",
    "- `dask` for parallelization\n",
    "- `sklearn` to build a confusion matrix\n",
    "- `seaborn` to plot a heatmap\n",
    "- `torch` for building, training, and evaluating the CNN\n",
    "\n",
    "If you do not have these packages installed, you can install them using `pip` or `conda`.\n",
    "\n",
    "## About this Notebook\n",
    "\n",
    "This notebook was written by Zach Claytor, an Astronomical Data Scientist at STScI.\n",
    "\n",
    "Contact: zclaytor@stsci.edu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcd18ec-010a-417f-8175-6c556d040e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import fft\n",
    "import matplotlib.pyplot as plt\n",
    "import lightkurve as lk\n",
    "import dask\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be6451d-cb48-460e-a583-53350ea6acfa",
   "metadata": {},
   "source": [
    "## 0. Set configuration parameters\n",
    "\n",
    "The cell below contains parameters that the user can use to configure the notebook run. First and foremost, the notebook contains two large computations: processing light curves into wavelet power spectra, and training the CNN. Both of these steps are precomputed, so they are not re-run by default. However, if you want to change any configurations and re-run them, you can by setting either of the first two variables to `True`.\n",
    "\n",
    "Other parameters include labels for the CNN run, which you can change so as not to overwrite existing save files, as well as CNN configurations: training batch size, early stopping patience, and the number of epochs to train for. \n",
    "\n",
    "The CNN exhibits a configurable number of convolution filters in each layer. In theory, more filters let you extract higher order features, but it can also result in overfitting. There are pre-defined configurations in the cells below (see the `channels` dict), where the configuration is set by `RUN_NUMBER`. We use the simplest configuration by default.\n",
    "\n",
    "`DEVICE` is the device on which to train the CNN. By default, it's the CPU, but if you have access to a CUDA-enabled GPU, you could swap \"cpu\" for \"cuda\".\n",
    "\n",
    "`LOSS_FUNCTION` is Cross Entropy by default, but you can also experiment with other loss functions. See [the PyTorch documentation](https://docs.pytorch.org/docs/stable/nn.html#loss-functions) for the possibilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1af794-146c-479c-b4dd-7b0cdae3da59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit this cell to modify the CNN run configuration\n",
    "\n",
    "# Choose whether to re-run computationally expensive steps\n",
    "RECOMPUTE_WAVELETS = False\n",
    "RETRAIN_CNN = False\n",
    "\n",
    "# Choose the run name and CNN configuration to use\n",
    "RUN_NAME = \"cnn\"  # Label for this run\n",
    "RUN_NUMBER = 0  # Which CNN channels configuration to use\n",
    "\n",
    "# IF RETRAINING\n",
    "BATCH_SIZE = 50  # Number of training examples to use per batch\n",
    "PATIENCE = 30  # Number of epochs to wait for loss to decrease before stopping\n",
    "MAX_EPOCHS = 500  # Maximum number of epochs to train before stopping\n",
    "TRAINING_COLS = [\"ebs\", \"exo\", \"flares\", \"rot\"]  # Which columns to use for training\n",
    "DEVICE = torch.device(\"cpu\")  # Which device to train the CNN on\n",
    "LOSS_FUNCTION = torch.nn.CrossEntropyLoss()  # Loss function to use\n",
    "TRAIN_SPLIT = [0.8, 0.1, 0.1]  # training/validation/test split\n",
    "\n",
    "# `model_name` becomes the base of the output file names.\n",
    "# It is {RUN_NAME}_{RUN_NUMBER} by default, but you can give it a custom label if desired.\n",
    "model_name = f\"{RUN_NAME}_{RUN_NUMBER}\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09d6ff6-0d30-456d-80ea-15aab41d5ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell uses the configurations above to do some basic setup. You can leave it alone.\n",
    "\n",
    "# Channel configurations\n",
    "channels = {\n",
    "    0: [8, 16, 32],\n",
    "    1: [16, 32, 64],\n",
    "    2: [32, 64, 128],\n",
    "    3: [64, 128, 256]\n",
    "}\n",
    "\n",
    "selected_channels = channels[RUN_NUMBER]\n",
    "\n",
    "# Normalize training split to add to 1\n",
    "TRAIN_SPLIT = np.array(TRAIN_SPLIT)/sum(TRAIN_SPLIT)\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(f\"runs/{model_name}\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03d5fee-8743-426d-994d-7f1e8b3ca510",
   "metadata": {},
   "source": [
    "## 1. Choose Training Set\n",
    "\n",
    "For our training set, we will use TESS-SPOC light curves of four types of objects, taken from the references below:\n",
    "- Eclipsing Binary Stars (\"ebs\"), [Prša et al. (2022)](https://ui.adsabs.harvard.edu/abs/2022ApJS..258...16P/abstract)\n",
    "- Exoplanet Transit Hosts (\"exo\"), [Exoplanet Follow-up Observing Program](https://exofop.ipac.caltech.edu/tess), queried 2025-05-05\n",
    "- Flaring Stars (\"flares\") [Günther et al. (2020)](https://ui.adsabs.harvard.edu/abs/2020AJ....159...60G/abstract)\n",
    "- Rotating Stars (\"rot\") [Kounkel et al. (2022)](https://ui.adsabs.harvard.edu/abs/2022AJ....164..137K/abstract)\n",
    "<!-- - Asteroseismic Oscillators (\"seis\") -->\n",
    "\n",
    "The data tables denoting the targets and sectors for which each event was detected are nonuniform, and conducting those queries is beyond the scope of this notebook. Instead, we've already undertaken the task of querying MAST for the light curves associated with the targets and sectors listed in these references. The files in the `data` folder have the cloud URIs so that we can read the light curves directly from the cloud without having to download them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c0b9ff-6085-47be-a79c-743ef4a652c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_uris(dataset, n_rows=1000):\n",
    "    # reads URIs from file, given dataset name\n",
    "    filepath = f\"data/tess-spoc-{dataset}-uris.txt\"\n",
    "    return np.loadtxt(filepath, dtype=str, max_rows=n_rows)\n",
    "\n",
    "\n",
    "def extract_meta(uri):\n",
    "    # converts URI into TIC ID, Sector pair\n",
    "    tic_id, sector = uri.split(\"_\")[4].split(\"-\")\n",
    "    tic_id = int(tic_id)\n",
    "    sector = int(sector[1:])\n",
    "    return tic_id, sector\n",
    "\n",
    "\n",
    "# Read the light curve URIs from file\n",
    "uris = {x: read_uris(x, n_rows=1000) for x in TRAINING_COLS}\n",
    "\n",
    "# Flatten URI dict and convert it to DataFrame.\n",
    "# We'll use this later.\n",
    "flat_uris = np.concatenate(list(uris.values()))\n",
    "uri_df = pd.Series({extract_meta(uri): uri for uri in flat_uris})\n",
    "uri_df = uri_df.to_frame(name=\"uri\").drop_duplicates()\n",
    "uri_df.index.names = [\"TIC\", \"sector\"]\n",
    "uri_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c586f0-603a-4f7d-a6c0-47a5915fe4c4",
   "metadata": {},
   "source": [
    "## 2. Preprocess Training Data\n",
    "\n",
    "Rather than using the raw light curves, we will leverage a 2D representation of the data that includes frequency information: the Morlet wavelet transform. This representation comes with several advantages:\n",
    "\n",
    "- Frequency transforms naturally concentrate frequency information spatially, which helps CNNs to interpret them.\n",
    "- The wavelet transform is a 2D representation, which lets us leverage image recognition algorithms.\n",
    "- Wavelet transforms can be binned down to small sizes (e.g., 64x64 pixels) without losing the most useful information.\n",
    "\n",
    "According to [Torrence and Compo (1998)](https://ui.adsabs.harvard.edu/abs/1998BAMS...79...61T/abstract), \"The continuous wavelet transform of a discrete sequence $x_n$ is defined as the convolution of $x_n$ with a scaled and translated version of [the mother wavelet] $\\psi_0 (\\eta)$\n",
    "\n",
    "$W_n(s) = \\sum_{n^\\prime = 0}^{N-1} x_{n^\\prime} \\psi^*\\left[\\frac{(n^\\prime - n)\\delta t}{s}\\right]$,\n",
    "\n",
    "and the Morlet wavelet as\n",
    "\n",
    "$\\psi_0 (\\eta) = \\pi^{-1/4} \\exp{(i \\omega_0 \\eta - \\eta^2 /2)}$.\n",
    "\n",
    "According to the convolution theorem, we can do the equivalent operation using the discrete Fourier transform. Here we will define the continuous wavelet transform as the inverse fast-Fourier transform (IFFT) of the product of the FFTs of the signal and conjugated wavelet.\n",
    "\n",
    "For more information on wavelet methods and implementations, see [Torrence and Compo (1998)](https://ui.adsabs.harvard.edu/abs/1998BAMS...79...61T/abstract) and the [`pycwt` documentation](https://pycwt.readthedocs.io)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a46600-4f7f-455d-bf92-631f5be8bb9b",
   "metadata": {},
   "source": [
    "### 2a. Define processing functions and show an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e270341a-1075-4dca-b7f4-0db8ebe76f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def morlet_wavelet_ft(w, w0=6):\n",
    "    \"\"\"Fourier transform of the Morlet wavelet\n",
    "    \"\"\"\n",
    "    return np.pi**(-0.25) * np.exp(-0.5 * (w - w0)**2)\n",
    "    \n",
    "    \n",
    "def cwt_morlet(signal, time, freqs, w0=6, pad=True):\n",
    "    \"\"\"Morlet wavelet transform as defined by, e.g., Torrence & Compo 1998.\n",
    "\n",
    "    Arguments:\n",
    "      signal (numpy array): the signal to be transformed\n",
    "      time (numpy array): the time array\n",
    "      freq (numpy array): the frequencies at which to evaluate the transform\n",
    "      w0 (float, default=6): the nondimensional frequency (tweaking this\n",
    "          affects the resolution at small versus large frequency scales.)\n",
    "      pad (bool, default=True); whether to zero pad the signal to the next\n",
    "          power of two length.\n",
    "\n",
    "    Returns:\n",
    "      cwt_norm (complex128 numpy array): the continuous wavelet transform,\n",
    "          normalized by scales to preserve energy conservation\n",
    "    \"\"\"\n",
    "    sig_norm = signal - np.mean(signal)\n",
    "    scales = (w0 + np.sqrt(2 + w0**2)) / (4*np.pi*freqs)\n",
    "    N = N_orig = len(time)\n",
    "    dt = time[1] - time[0]\n",
    "    \n",
    "    if pad:\n",
    "        next_pow_2 = int(2**np.ceil(np.log2(N)))\n",
    "        sig_norm = np.pad(sig_norm, (0, next_pow_2-N))\n",
    "        N = next_pow_2\n",
    "\n",
    "    # Compute signal FFT\n",
    "    signal_ft = fft.fft(sig_norm, n=N)\n",
    "\n",
    "    # Fourier angular frequencies\n",
    "    ftfreqs = 2*np.pi*fft.fftfreq(N, dt)\n",
    "    # Set up wavelet grid for each scale\n",
    "    psi_ft = np.sqrt(2*np.pi*scales[:, None]/dt) * morlet_wavelet_ft(scales[:, None] * ftfreqs).conj()\n",
    "    # Compute IFFT to produce the wavelet transform\n",
    "    cwtmat = fft.ifft(signal_ft * psi_ft, axis=1)\n",
    "\n",
    "    cwt_scaled = cwtmat[:, :N_orig]/scales[:, None]**0.5\n",
    "    return cwt_scaled\n",
    "\n",
    "\n",
    "def reshape_power(power, output_size=64):\n",
    "    \"\"\"Use PyTorch's tensor operations to bin the power spectrum\n",
    "    \"\"\"\n",
    "    if isinstance(output_size, int):\n",
    "        output_size = (output_size, output_size)\n",
    "        \n",
    "    power_tensor = torch.tensor(np.expand_dims(power, 0))\n",
    "    \n",
    "    power = torch.nn.functional.adaptive_avg_pool2d(power_tensor, output_size=output_size)\n",
    "    return np.squeeze(power.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb83f9c6-ee93-4b9a-a3a1-d3c5964d1b9e",
   "metadata": {},
   "source": [
    "Now let's see an example. For the first rotating star light curve, we'll look at\n",
    "1. the light curve\n",
    "2. the wavelet transform\n",
    "3. the binned wavelet transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db820806-2f1e-46d2-96cd-5fdb09df44dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = uris[\"rot\"][0]\n",
    "lc = lk.read(uri)\n",
    "\n",
    "# Plot the light curve\n",
    "lc.plot()\n",
    "\n",
    "# Remove NaNs and fill gaps\n",
    "lc = lc.remove_nans().fill_gaps()\n",
    "time = lc.time.value\n",
    "flux = lc.flux.value\n",
    "\n",
    "# Compute and plot the wavelet transform\n",
    "freq = np.geomspace(1/10, 10, 512)\n",
    "power = cwt_morlet(flux, lc.time.value, freq)\n",
    "\n",
    "plt.figure()\n",
    "im = plt.pcolormesh(time, 1/freq, np.abs(power), shading=\"nearest\")\n",
    "plt.yscale(\"log\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.xlabel(\"Time (days)\")\n",
    "plt.ylabel(\"Period (days)\")\n",
    "plt.colorbar(im, label=\"Power (arbitrary units)\")\n",
    "\n",
    "# Bin the wavelet transform and plot it\n",
    "binned_power = reshape_power(np.abs(power))\n",
    "plt.figure()\n",
    "plt.imshow(binned_power, origin=\"lower\")\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b554afe7-209b-46c2-8394-ba283eec9f3f",
   "metadata": {},
   "source": [
    "The light curve shows a strong signal that repeats slightly faster than once per day. Taking the wavelet transform, this signal results in a horizontal band of power at around 0.7 day, and a slightly weaker band at 1.4 day. There is a gap halfway through the time axis corresponding to a gap in the light curve when the telescope briefly stopped taking data in order to downlink to Earth. Binning the wavelet transform, all this information is still preserved, but the image is much smaller in memory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f21e35a-1e4b-4c58-a914-88d8a646f093",
   "metadata": {},
   "source": [
    "### 2b. Process all light curves\n",
    "\n",
    "We will loop over all the light curves to generate and save wavelet power spectra. We can accelerate this process using parallelization with `dask`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ef775c-4603-45c1-aad9-a4b5665f00c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to process one light curve\n",
    "def process_lc(uri, class_label, flux_column=\"PDCSAP_FLUX\", quality_bitmask=\"default\"):\n",
    "    lc = lk.read(\n",
    "        uri, # the path to the light curve in the cloud\n",
    "        # flux_column=flux_column, # which column to set as the flux\n",
    "        # quality_bitmask=quality_bitmask, # remove bad data\n",
    "    )\n",
    "    \n",
    "    # Remove NaNs and fill gaps\n",
    "    lc = lc.remove_nans().fill_gaps()\n",
    "    \n",
    "    # Compute the wavelet transform\n",
    "    freq = np.geomspace(1/10, 12, 512)\n",
    "    power = cwt_morlet(lc.flux.value, lc.time.value, freq)\n",
    "    \n",
    "    binned_power = reshape_power(np.abs(power)) # bin the power spectrum\n",
    "    binned_power -= binned_power.min() # normalize the power spectrum to [0, 255]\n",
    "    binned_power *= 255/binned_power.max()\n",
    "    binned_power = binned_power.astype(np.uint8) # convert to 8-bit integers\n",
    "    \n",
    "    # Save normalized power spectrum\n",
    "    basename = os.path.basename(uri).replace(\"lc.fits\", \"wps.npy\")\n",
    "    np.save(os.path.join(\"data\", class_label, basename), binned_power)\n",
    "\n",
    "    print(os.path.join(class_label, basename), \"done.\")\n",
    "    return binned_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e48a244-01a3-4c86-8b28-ebdc701b18c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if RECOMPUTE_WAVELETS:\n",
    "    # Create data subdirectories\n",
    "    for c in TRAINING_COLS:\n",
    "        os.makedirs(os.path.join(\"data\", c), exist_ok=True)\n",
    "    \n",
    "    # Set up Dask job\n",
    "    lazy_results = []\n",
    "    for c in TRAINING_COLS:\n",
    "        for uri in uris[c]:\n",
    "            lazy_result = dask.delayed(process_lc)(uri, c)\n",
    "            lazy_results.append(lazy_result)\n",
    "    \n",
    "    # Run Dask job\n",
    "    wavelets = dask.compute(*lazy_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71cd5b6-02a2-47a8-966f-91f49308c79b",
   "metadata": {},
   "source": [
    "### 2c. Build a container for the training data\n",
    "\n",
    "PyTorch gives users the ability to train in batches using their Dataset and DataLoader classes. Training with the right batch size helps the optimizer to find minima more quickly in the loss space, which can accelerate training. Here we will set up a custom dataset class to take advantage of batch training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8a3281-70f4-4f65-8ad8-6e0df56c68e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveletDataset(Dataset):\n",
    "    \"\"\"Custom dataset class for loading wavelet data from files.\n",
    "\n",
    "    This class is responsible for loading wavelet data and corresponding labels\n",
    "    from the specified file paths. It supports splitting the data into training,\n",
    "    validation, and test sets.\n",
    "\n",
    "    Attributes:\n",
    "        features (np.ndarray): Array containing the light curve wavelet transforms.\n",
    "        labels (np.ndarray): Array containing the classifications for each light curve.\n",
    "        columns (list of str): List of names of classification columns.\n",
    "    \"\"\"    \n",
    "    def __init__(self, data, columns):\n",
    "        \"\"\"\n",
    "        Initialize the dataset.\n",
    "        \n",
    "        Args:\n",
    "            data (DataFrame): the DataFrame containing the wavelet and classification data.\n",
    "                Wavelet data should be in a column labeled 'wavelet', while the classification\n",
    "                columns must be specified by the `columns` argument.\n",
    "            columns (list of str): list of names of classification columns to use.\n",
    "        \"\"\" \n",
    "        self.features = data[\"wavelet\"].values\n",
    "        self.labels = data[columns].values\n",
    "        self.columns = columns\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the length of the dataset.\"\"\"\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Retrieve a single sample and its corresponding label.\n",
    "\n",
    "        Args:\n",
    "            idx (int): The index of the sample to retrieve.\n",
    "\n",
    "        Returns:\n",
    "            tuple: A tuple containing the sample data (torch.Tensor) and the \n",
    "                   corresponding label (torch.Tensor).\n",
    "        \"\"\"\n",
    "        X = self.features[idx].astype(\"float32\")\n",
    "        X = torch.unsqueeze(torch.tensor(X), 0)\n",
    "        label = torch.tensor(self.labels[idx].astype(\"float32\"))\n",
    "        return X, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77da4c4-1c39-4147-bf95-1d35cf9d6653",
   "metadata": {},
   "source": [
    "Now we will put the training data into a DataFrame before passing to the WaveletDataset class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29397a8b-9717-48c0-975f-d47d423d36cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up dataframe\n",
    "training_data = pd.DataFrame([], columns=[\"TIC\", \"sector\", *TRAINING_COLS, \"wavelet\"])\n",
    "training_data.index.name = \"filename\"\n",
    "\n",
    "# Iterate over wavelet files, adding them to the dataframe\n",
    "for i, col in enumerate(TRAINING_COLS):\n",
    "    for s in os.listdir(os.path.join(\"data\", col)):\n",
    "        if not s.endswith(\".npy\"):\n",
    "            continue\n",
    "        if s not in training_data.index:\n",
    "            wav = np.load(os.path.join(\"data\", col, s))\n",
    "            tic_id, sector = s.split(\"_\")[4].split(\"-\") # split target name field\n",
    "            tic_id = int(tic_id)\n",
    "            sector = int(sector[1:]) # trim off leading 's'\n",
    "            training_data.loc[s] = [tic_id, sector, *([0]*len(TRAINING_COLS)), wav/wav.max()]\n",
    "        training_data.loc[s, col] = 1\n",
    "\n",
    "training_data = training_data.reset_index().set_index([\"TIC\", \"sector\"]).sort_index()\n",
    "\n",
    "# Normalize the class identification\n",
    "training_data[TRAINING_COLS] = training_data[TRAINING_COLS].div(training_data[TRAINING_COLS].sum(axis=1), axis=0)\n",
    "\n",
    "# Filter out rows that have multiple classes\n",
    "training_data = training_data[training_data[TRAINING_COLS].max(axis=1) == 1]\n",
    "\n",
    "# grab top 1000 rows for each class\n",
    "training_data = pd.concat([training_data.query(f\"{c} == 1\").iloc[:1000] for c in TRAINING_COLS]).sort_index()\n",
    "\n",
    "# join with light curve URIs from earlier\n",
    "training_data = training_data.join(uri_df)\n",
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e5c5f7-3e41-4470-9a0f-bc036ce9d2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast DataFrame to WaveletDataset\n",
    "wavelet_data = WaveletDataset(training_data, columns=TRAINING_COLS)\n",
    "\n",
    "# Randomly partition the data between training, validation, and test sets\n",
    "generator1 = torch.Generator().manual_seed(42)\n",
    "train_set, validation_set, test_set = random_split(wavelet_data, lengths=TRAIN_SPLIT, generator=generator1)\n",
    "\n",
    "# Cast datasets to DataLoaders for training in batches\n",
    "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE)\n",
    "validation_loader = DataLoader(validation_set, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da79a06-3314-4010-9da9-0478777955ee",
   "metadata": {},
   "source": [
    "## 3. Build the CNN Classifier\n",
    "\n",
    "The CNN exhibits the following attributes:\n",
    "- 2D convolution layers to extract features from wavelet images\n",
    "- Configurable number of convolution filters\n",
    "- 1D max-pooling in the time dimension for dimensionality reduction while preserving frequency resolution\n",
    "- 2D batch normalization to keep weights stable\n",
    "- ReLU activation to keep values non-negative\n",
    "- Dropout to build in redundancy\n",
    "- Softmax output for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0149f975-d54a-43e4-b4c9-7cc6be2ed7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, c=[8, 16, 32], k=3, n_output=4):\n",
    "        if isinstance(k, int):\n",
    "            k = [k]*len(c)\n",
    "        n_nodes = (64 - (sum(k) - len(k))) * c[-1]\n",
    "\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,  c[0], k[0], 1) # 62 x 20\n",
    "        self.conv1_bn = nn.BatchNorm2d(c[0])\n",
    "        self.conv2 = nn.Conv2d(c[0], c[1], k[1], 1) # 60 x 6 \n",
    "        self.conv2_bn = nn.BatchNorm2d(c[1])\n",
    "        self.conv3 = nn.Conv2d(c[1], c[2], k[2], 1) # 58 x 1\n",
    "        self.conv3_bn = nn.BatchNorm2d(c[2])\n",
    "        \n",
    "        self.fc1 = nn.Linear(n_nodes, 256) # 58 x 32 = 1856\n",
    "        self.fc1_bn = nn.BatchNorm1d(256)\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.fc2_bn = nn.BatchNorm1d(64)\n",
    "        self.fc3 = nn.Linear(64, n_output)\n",
    "        \n",
    "        self.dropout1 = nn.Dropout(0.1)\n",
    "        self.dropout2 = nn.Dropout2d(0.1)\n",
    "\n",
    "    def forward(self, x, return_embeddings=False):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv1_bn(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, (1, 3))\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv2_bn(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, (1, 3))\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv3_bn(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, (1, x.shape[-1]))\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc1_bn(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc2_bn(x)\n",
    "\n",
    "        if return_embeddings:\n",
    "            return x\n",
    "        \n",
    "        x = F.relu(x)\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        output = self.fc3(x)\n",
    "        output = F.softmax(output, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12386ee0-bcaf-4ce5-a774-470d6a354b78",
   "metadata": {},
   "source": [
    "## 4. Train the CNN\n",
    "\n",
    "We train the CNN using the `Adam` optimizer, which uses adaptive learning rates (LR) to train the network. To vary the LR, we use a plateau scheduler (`ReduceLROnPlateau`), which reduces the LR when the loss plateaus. This enables the CNN parameters to find local minima more easily, rather than take large steps over them.\n",
    "\n",
    "Finally, we will also use an early stopping criterion. This means that if the validation loss plateaus or increases for a certain number of epochs, training stops early, and the best fit CNN values are saved.\n",
    "\n",
    "First we will define our training function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9272f773-fd10-4d81-b2d0-24309b5a0e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, val_loader, patience, max_epochs, model_name=\"cnn\"):\n",
    "    \"\"\"Train the neural network for the specified number of epochs.\n",
    "\n",
    "    This function orchestrates the training loop, updating model weights based on\n",
    "    the training data, validating the model on a validation set, and handling\n",
    "    early stopping based on validation loss.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The neural network model to be trained.\n",
    "        device (torch.device): The device (CPU or GPU) on which to perform training.\n",
    "        train_loader (DataLoader): DataLoader for the training dataset.\n",
    "        val_loader (DataLoader): DataLoader for the validation dataset.\n",
    "        patience (int): Early stopping patience.\n",
    "        max_epochs (int): Maximum number of training iterations.\n",
    "        model_name (str): The name of the model, used for saving the trained weights.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the best model weights, training losses, and validation losses.\n",
    "    \"\"\"\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, factor=0.7, patience=3)\n",
    "    \n",
    "    train_losses, val_losses = [], []\n",
    "    min_loss = float(\"inf\")\n",
    "    early_stopping_count = 0\n",
    "    best_weights = None\n",
    "\n",
    "    for epoch in range(1, max_epochs + 1):\n",
    "        train_loss = train_epoch(model, device, train_loader, optimizer, epoch)\n",
    "        val_loss = test(model, device, val_loader, epoch, model_name, mode=\"Validation\")\n",
    "        \n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        if val_loss < min_loss:\n",
    "            min_loss = val_loss\n",
    "            early_stopping_count = 0\n",
    "            best_weights = deepcopy(model.state_dict())\n",
    "        else:\n",
    "            early_stopping_count += 1\n",
    "            print(f\"        Early Stopping count: {early_stopping_count}/{patience}\")\n",
    "            if early_stopping_count == patience:\n",
    "                print(f\"\\nEarly Stopping. Best Epoch: {epoch - patience} with loss {min_loss:.4f}.\")\n",
    "                break\n",
    "\n",
    "    return best_weights, train_losses, val_losses\n",
    "\n",
    "\n",
    "def train_epoch(model, device, train_loader, optimizer, epoch):\n",
    "    \"\"\"Train the model for one epoch.\n",
    "\n",
    "    This function processes each batch of training data, computes the loss,\n",
    "    and updates the model weights accordingly.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The neural network model to be trained.\n",
    "        device (torch.device): The device (CPU or GPU) for training.\n",
    "        train_loader (DataLoader): DataLoader for the training dataset.\n",
    "        optimizer (torch.optim.Optimizer): The optimizer used for weight updates.\n",
    "        epoch (int): The current epoch number.\n",
    "\n",
    "    Returns:\n",
    "        float: The average loss for the epoch.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    losses = []\n",
    "\n",
    "    ndata = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = LOSS_FUNCTION(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "        ndata += len(data)\n",
    "        print(\n",
    "            f\"Train Epoch: {epoch:3d} [{ndata:6d}/{len(train_loader.dataset)}\"\n",
    "            f\" ({100*ndata/len(train_loader.dataset):3.0f}%)]\\tLoss: {losses[-1]:.6f}\",\n",
    "            end=\"\\r\")\n",
    "\n",
    "    return np.mean(losses)\n",
    "\n",
    "\n",
    "def test(model, device, test_loader, epoch=None, model_name=None, mode=\"Validation\"):\n",
    "    \"\"\"Evaluate the model on the test set.\n",
    "\n",
    "    This function assesses the model's performance on a specified dataset\n",
    "    and computes the average loss. It can also generate a plot of predictions\n",
    "    versus true values.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The neural network model to be evaluated.\n",
    "        device (torch.device): The device (CPU or GPU) for evaluation.\n",
    "        test_loader (DataLoader): DataLoader for the test dataset.\n",
    "        epoch (int, optional): The current epoch number (for labeling purposes).\n",
    "        model_name (str, optional): The name of the model (for labeling purposes).\n",
    "        mode (str, optional): Indicates whether the evaluation is for training, validation, or testing.\n",
    "\n",
    "    Returns:\n",
    "        float: The average loss on the test set.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    targets, preds = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            targets.extend(target.cpu().numpy())\n",
    "            preds.extend(output.cpu().numpy())\n",
    "            test_loss += LOSS_FUNCTION(output, target).item()\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    print(f\"\\n                     Average {mode} Loss: {test_loss:.4f}\")\n",
    "\n",
    "    if mode.lower() == \"test\":\n",
    "        return np.squeeze(preds), np.squeeze(targets), test_loss\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a65ac5-a7ee-479f-8e1e-e41c509bf130",
   "metadata": {},
   "source": [
    "If `RETRAIN_CNN==True`, we will train the CNN here. Otherwise, we will load the default weights from file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6230661a-3082-4bb7-a7d0-1e471a8aa6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet(selected_channels, k=3, n_output=len(TRAINING_COLS)).to(DEVICE)\n",
    "\n",
    "if RETRAIN_CNN:\n",
    "    # Train the CNN\n",
    "    # weights, train_losses, validation_losses = train(model, DEVICE, train_loader, validation_loader, PATIENCE, MAX_EPOCHS, model_name)\n",
    "    torch.save(weights, os.path.join(\"runs\", model_name, f\"{model_name}.pt\"))\n",
    "    np.save(\n",
    "        os.path.join(\"runs\", model_name, f\"{model_name}_loss.npy\"), \n",
    "        np.stack([train_losses, validation_losses])\n",
    "    )\n",
    "else:\n",
    "    # Load weights from file\n",
    "    weights = torch.load(f\"runs/{model_name}/{model_name}.pt\")\n",
    "    train_losses, validation_losses = np.load(os.path.join(\"runs\", model_name, f\"{model_name}_loss.npy\"))\n",
    "    \n",
    "# Evaluate best-fit model\n",
    "model.load_state_dict(weights)\n",
    "print(\"\\nFinal Performance!\")\n",
    "test(model, DEVICE, train_loader, mode=\"Training\")\n",
    "test(model, DEVICE, validation_loader, mode=\"Validation\")\n",
    "test_preds, test_labels, test_loss = test(model, DEVICE, test_loader, mode=\"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37ec05b-bea9-402e-b9f6-b51ce1779f8a",
   "metadata": {},
   "source": [
    "Now that the CNN is trained, we should take a look at the \"learning curves,\" or the loss over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db0d95d-a4ec-408e-8035-36084169c606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot learning curve\n",
    "plt.figure()\n",
    "plt.plot(train_losses, label=\"Training Loss\")\n",
    "plt.plot(validation_losses, label=\"Validation Loss\", alpha=0.5)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6f7bcf-d973-4dc4-99dd-86a3cc8da02d",
   "metadata": {},
   "source": [
    "While `MAX_EPOCHS` was set to 500 by default, the training function checked the value of the validation loss to see if it plateaued for 30 epochs. When it did, training was declared to be finished, and the best-fit weights were saved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3ec5cd-08be-4686-8f4d-60caea83292c",
   "metadata": {},
   "source": [
    "## 5. Evaluate CNN Performance\n",
    "\n",
    "Now that training is complete, it's useful to evaluate the CNN on the held-out test set to see how accurately it classifies data that it hasn't seen before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276b4be4-883a-4c9e-adb6-44143a91d98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join test set predictions with the input data\n",
    "test_df = training_data.iloc[test_set.indices].copy()\n",
    "test_df.loc[:, [c + \"_pred\" for c in wavelet_data.columns]] = test_preds\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62698901-b8a3-4865-b584-3128f3fb494f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the prediction for each light curve to be the class with the highest probability\n",
    "prediction = test_df[[c + \"_pred\" for c in TRAINING_COLS]].values.argmax(axis=1)\n",
    "truth = test_df[TRAINING_COLS].values.argmax(axis=1)\n",
    "\n",
    "# Create a confusion matrix to look at accuracy and false positive/negatives\n",
    "cm = confusion_matrix(truth, prediction)\n",
    "cm = cm.astype(float)/cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Visualize confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "seaborn.heatmap(cm, annot=True, fmt=\".2f\", cmap=\"Blues\", xticklabels=TRAINING_COLS, yticklabels=TRAINING_COLS)\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f4f9a1-a0a1-42df-8581-08ca8c6d78db",
   "metadata": {},
   "source": [
    "The example CNN classifies unseen data with 77% accuracy or better. The failure modes are interesting:\n",
    "- True EBs are often misclassified as (a) exoplanet transits or (b) rotators. This is likely because (a) the shape of a binary eclipse resembles that of a planet transit, and (b) EBs are often rapidly rotating due to binary interactions, so they may also exhibit rotation signatures.\n",
    "- While transiting exoplanets are accurately classified 86% of the time, the failure modes are all equally likely.\n",
    "- Flaring stars are not likely to be misclassified as rotators, but rotators are likely to be misclassified as flaring stars. Rapid rotators often also exhibit flares, so the latter isn't too surprising, but it's interesting that the converse doesn't occur as well.\n",
    "\n",
    "All in all, the predictions make physical sense, but definitely require some digging to understand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616321f5-f90d-4b24-a438-b8f98832503d",
   "metadata": {},
   "source": [
    "## 6. Extract Embeddings and Conduct the Similarity Search\n",
    "\n",
    "Now that we have verified that the CNN is properly trained, we can extract the feature embeddings and perform the similarity search. We'll first get the embedding vectors of the test set, then pick a random light curve, and then get the 10 most similar ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176c91a2-cba5-4d5f-b5e5-23f644d8af90",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RETRAIN_CNN:\n",
    "    # We only need to extract the embeddings if the CNN was retrained\n",
    "    test_data = wavelet_data.features[test_set.indices]\n",
    "    tdata = torch.tensor(np.stack(test_data), dtype=torch.float32).unsqueeze(1)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # We built the CNN with a special clause to export the embeddings during forward propagation\n",
    "        embeddings = model.forward(tdata, return_embeddings=True).numpy()\n",
    "\n",
    "    # Save the embeddings to file\n",
    "    np.save(os.path.join(\"runs\", model_name, f\"{model_name}_embeddings.npy\"), embeddings)\n",
    "else:\n",
    "    # Otherwise we just read the old ones from file\n",
    "    embeddings = np.load(os.path.join(\"runs\", model_name, f\"{model_name}_embeddings.npy\"))\n",
    "\n",
    "# Add the embeddings to the test DataFrame\n",
    "test_df.loc[:, \"embedding\"] = list(embeddings)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbc3f2e-542a-412c-bca9-84ff04c5a04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For our \"test target\", we'll pop the first row of the test DataFrame.\n",
    "my_row = test_df.iloc[0]\n",
    "popped_df = test_df.drop(my_row.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8267517d-46d7-4fa6-9990-941b87f74dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell contains the actual similarity search. The steps are:\n",
    "#  1. Recall the embeddings,\n",
    "#  2. Compute the distance between the test point and all other embedding vectors\n",
    "#  3. Return the closest 10 targets\n",
    "\n",
    "points = np.stack(popped_df[\"embedding\"].to_numpy())\n",
    "dists = np.linalg.norm(points - my_row[\"embedding\"], axis=1)\n",
    "\n",
    "popped_df[\"dist\"] = dists\n",
    "closest = popped_df.nsmallest(10, \"dist\")\n",
    "closest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8396915d-d2f7-4cf2-affc-4272263618ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-25T20:18:49.714415Z",
     "iopub.status.busy": "2025-08-25T20:18:49.714065Z",
     "iopub.status.idle": "2025-08-25T20:18:49.751821Z",
     "shell.execute_reply": "2025-08-25T20:18:49.750867Z",
     "shell.execute_reply.started": "2025-08-25T20:18:49.714389Z"
    }
   },
   "source": [
    "### Visualize \"similar\" light curves\n",
    "\n",
    "Now that we have performed the similarity search, we should visualize the returned light curves to decide whether or not we believe that they are similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160774ff-d034-4fa9-835f-67d8d9337a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read light curves\n",
    "for i, row in closest.iterrows():\n",
    "    closest.loc[i, \"lightcurve\"] = lk.read(training_data.loc[i, \"uri\"])\n",
    "\n",
    "my_lc = lk.read(training_data.loc[my_row.name, \"uri\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd504032-cc81-4faf-a22b-6c4a7be33b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the \"target\" light curve\n",
    "ax = my_lc.plot()\n",
    "ax.legend().remove()\n",
    "ax.set_title(f\"TIC {my_lc.ticid}, Sector {my_lc.sector}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd890a4-10ca-46ec-84d3-c3336c13a1dd",
   "metadata": {},
   "source": [
    "The target light curve appears to be an eclipsing binary or an ellipsoidal variable (note that we didn't have a separate class for ellipsoidal variations). But how do the \"similar\" light curves compare?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ef4cf5-7819-494b-a43f-7395ecb5e927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the top 10 most similar light curves\n",
    "for i, row in closest.iterrows():\n",
    "    lc = row[\"lightcurve\"]\n",
    "    ax = lc.plot()\n",
    "    ax.legend().remove()\n",
    "    ax.set_title(f\"TIC {lc.ticid}, Sector {lc.sector}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdad5f7d-c81a-4c2d-9c08-631b001efe6a",
   "metadata": {},
   "source": [
    "All 10 of the returned similar light curves appear to have the same kinds of ellipsoidal variations and/or binary eclipses. Remember that the similarity search is agnostic to the actual classifications---it's performed on extracted features of the light curves alone!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e1fd07-a14c-462a-be47-cd4afe7183ec",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook we developed a light curve similarity search using a CNN classifier to learn and export feature embeddings from the light curves. We selected and processed training data, built and trained the CNN, extracted the embeddings, and showed an example of a similarity search. Similarity Searches are powerful because they do not rely on metadata in the same way classical database queries do. Instead, they rely only on features of the data. This kind of search can empower users to build science samples without needing to know *a priori* what kinds of objects produce the features they see in the data.\n",
    "\n",
    "## Exercises\n",
    "\n",
    "In this example, we used a single CNN configuration to build the similarity search, but there are other configurations and choices that may be enlightening. For example,\n",
    "1. Use different numbers of convolution filters by changing `RUN_NUMBER`, or if you're feeling daring, manually configure the CNN `channels`.\n",
    "2. Train on fewer training classes by removing a column from `TRAINING_COLS`. You may find that adding or removing classes affects the classification accuracy.\n",
    "3. Use different \"test\" examples for the similarity search. Do the returned light curves look similar?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
