

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Estimating TESS rotation periods with CNNs &#8212; Hello Universe!</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" href="../../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/table.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'notebooks/hello-universe/Estimating_TESS_rotation_periods_with_CNNs/Estimating_TESS_rotation_periods_with_CNNs';</script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../../_static/HelloUniverseLogo.png" class="logo__image only-light" alt="Hello Universe! - Home"/>
    <script>document.write(`<img src="../../../_static/HelloUniverseLogo.png" class="logo__image only-dark" alt="Hello Universe! - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../../intro.html">
                    Hello Universe
                </a>
            </li>
        </ul>
        <ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../Classifying_TESS_flares_with_CNNs/Classifying_TESS_flares_with_CNNs.html">Classifying flaring stars with stella: a convolutional neural network for TESS</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Classifying_JWST-HST_galaxy_mergers_with_CNNs/Classifying_JWST-HST_galaxy_mergers_with_CNNs.html">Classifying JWST-HST galaxy mergers with CNNs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Regressing_3D-HST_galaxy_redshift_with_decision_trees/Regressing_3D-HST_galaxy_redshift_with_decision_trees.html">Predicting galaxy redshift via regression on 3D-HST photometry</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Classifying_PanSTARRS_sources_with_unsupervised_learning/Classifying_PanSTARRS_sources_with_unsupervised_learning.html">Classifying Pan-STARRS sources with unsupervised and supervised learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Interpreting_CNNs/Interpreting_CNNs.html">Interpreting Convolutional Neural Networks</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/spacetelescope/hellouniverse" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/spacetelescope/hellouniverse/issues/new?title=Issue%20on%20page%20%2Fnotebooks/hello-universe/Estimating_TESS_rotation_periods_with_CNNs/Estimating_TESS_rotation_periods_with_CNNs.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../../_sources/notebooks/hello-universe/Estimating_TESS_rotation_periods_with_CNNs/Estimating_TESS_rotation_periods_with_CNNs.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Estimating TESS rotation periods with CNNs</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction">Introduction</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#goals">Goals</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#runtime">Runtime</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#installs-and-imports">Installs and Imports</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#configure-training-run">0. Configure training run</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#prepare-training-data">1. Prepare training data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#build-the-cnn">2. Build the CNN</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#define-training-validation-and-evaluation-functions">3. Define training, validation, and evaluation functions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#train-the-cnn-on-smarts-data">4. Train the CNN on SMARTS data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#test-the-cnn-performance">5. Test the CNN performance</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#summary">Summary</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#next-steps">Next Steps</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#references">References</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="estimating-tess-rotation-periods-with-cnns">
<h1>Estimating TESS rotation periods with CNNs<a class="headerlink" href="#estimating-tess-rotation-periods-with-cnns" title="Permalink to this heading">#</a></h1>
<section id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this heading">#</a></h2>
<p>The NASA TESS mission conducts an all-sky survey searching for exoplanets that transit their host stars. To do so, it collects time series photometry called “light curves” for millions of stars across the sky. These light curves have many science uses besides exoplanets, including stellar rotation. As a star rotates, cool magnetic spots come into and out of view, causing periodic wiggles in the brighness measurements through time. We can therefore use light curves from TESS to infer stellar rotation periods, which are useful for studying stellar magnetism, structure, and ages.</p>
<p>However, systematics associated with the telescope’s special Earth-Moon orbit make it difficult to measure long (&gt; 13 day) rotation periods from TESS light curves using conventional frequency analysis techniques. Machine learning methods, and in particular Convolutional Neural Networks (CNN) have been shown to circumvent some of the effects of systematics and estimate rotation periods from TESS light curves and their frequency transforms.</p>
<p>In this tutorial we will use a CNN to estimate stellar rotation periods from frequency transforms of TESS light curves. For our training set, we will use the simulations from the MAST High Level Science Product <a class="reference external" href="https://archive.stsci.edu/hlsp/smarts">SMARTS</a>. SMARTS combines physically realistic simulations of rotational light curves with real noise and systematics from TESS. This combination allows CNNs to learn the difference between rotation signals and systematics and estimate stellar rotation periods.</p>
</section>
<section id="goals">
<h2>Goals<a class="headerlink" href="#goals" title="Permalink to this heading">#</a></h2>
<p>The goal of this notebook is to use <a class="reference external" href="https://archive.stsci.edu/hlsp/smarts">SMARTS</a> data to train a CNN to regress TESS rotation periods. We will</p>
<ol class="arabic simple" start="0">
<li><p><span class="xref myst">Configure the training run</span>,</p></li>
<li><p><span class="xref myst">Prepare the training data</span>,</p></li>
<li><p><span class="xref myst">Build the CNN</span>,</p></li>
<li><p><span class="xref myst">Define training, validation, and evaluation functions</span>,</p></li>
<li><p><span class="xref myst">Train the CNN</span>, and</p></li>
<li><p><span class="xref myst">Test the CNN performance</span>.</p></li>
</ol>
<p>The training examples are 2-dimensional arrays of wavelet transforms of TESS light curves. The wavelet transform concentrates the periodicity of the light curve, making it easier for a CNN to regress the period. CNNs take advantage of the image-like nature of a wavelet transform in the same way that CNNs are useful for image recognition and computer vision.</p>
</section>
<section id="runtime">
<h2>Runtime<a class="headerlink" href="#runtime" title="Permalink to this heading">#</a></h2>
<p>On the <a class="reference external" href="https://timeseries.science.stsci.edu">TIKE</a> “Large” instance, this notebook takes just under 3 minutes to run from start to finish. The bulk of this time is spent downloading the training data. Once you’ve done that once, you can comment out the cell, and the notebook will be faster.</p>
<p>This notebook, including the CNN training, is configured to run on a single CPU.</p>
</section>
<section id="installs-and-imports">
<h2>Installs and Imports<a class="headerlink" href="#installs-and-imports" title="Permalink to this heading">#</a></h2>
<p>This notebook uses the following packages:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">glob</span></code> for generating lists of training files</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">copy</span></code> for saving training weights</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">numpy</span></code> for array operations</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">matplotlib</span></code> for plotting</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">astropy</span></code> for reading FITS files</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">torch</span></code> for tensor and CNN operations</p></li>
</ul>
<p>You can install the requirements by running <code class="docutils literal notranslate"><span class="pre">%pip</span> <span class="pre">install</span> <span class="pre">-r</span> <span class="pre">requirements.txt</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">glob</span><span class="w"> </span><span class="kn">import</span> <span class="n">glob</span>  <span class="c1"># for generating lists of input files</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">copy</span><span class="w"> </span><span class="kn">import</span> <span class="n">deepcopy</span>  <span class="c1"># for saving CNN weights</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>  <span class="c1"># array operations</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">astropy.io</span><span class="w"> </span><span class="kn">import</span> <span class="n">fits</span>  <span class="c1"># FITS file operations</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>  <span class="c1"># for plotting</span>

<span class="c1"># For tensor and CNN operations</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span> 
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn.functional</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">F</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">optim</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">DataLoader</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="configure-training-run">
<h2>0. Configure training run<a class="headerlink" href="#configure-training-run" title="Permalink to this heading">#</a></h2>
<p>Before we get started, we need to set some configuration parameters to know how much data to read in, and how many epochs to train for. Ideally, we want to run on the full training set (<code class="docutils literal notranslate"><span class="pre">max_n</span> <span class="pre">=</span> <span class="pre">1_000_000</span></code>) for long enough that the loss plateaus (usually <code class="docutils literal notranslate"><span class="pre">num_epochs</span> <span class="pre">=</span> <span class="pre">500</span></code>). But this for this simple demo, we will use a subset of training data and a shorter training time. We will train/validation/test using a 80%/10%/10% <code class="docutils literal notranslate"><span class="pre">split</span></code>, and we’ll build a CNN with 3 convolution layers with filter depths increasing from 8, to 16, to 32 <code class="docutils literal notranslate"><span class="pre">filters</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">max_n</span> <span class="o">=</span> <span class="mi">10_000</span>  <span class="c1"># max 1_000_000</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">20</span>  <span class="c1"># 100 is pretty good, typically ~300 to 500 to reach a plateau</span>
<span class="n">split</span> <span class="o">=</span> <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>  <span class="c1"># ratios for train/validation/test split</span>
<span class="n">filters</span> <span class="o">=</span> <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">32</span><span class="p">]</span>  <span class="c1"># list of CNN layer filter depths</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="prepare-training-data">
<h2>1. Prepare training data<a class="headerlink" href="#prepare-training-data" title="Permalink to this heading">#</a></h2>
<p>The SMARTS training data are in the form of continuous Morlet wavelet transforms (CWTs) or wavelet power spectra (WPS). Rather than train on the light curve itself, the WPS provides a 2D representation of the frequency information present in the light curve. With frequency or period on the y-axis and time on the x-axis, the WPS illustrates which frequencies dominate the light curve at different times. Since it is effectively an image, we can take advantage of image recognition capabilities of CNNs.</p>
<p>For more information on CWTs, see</p>
<ul class="simple">
<li><p><a class="reference external" href="https://ui.adsabs.harvard.edu/abs/1998BAMS...79...61T/abstract"><em>A Practical Guide to Wavelet Analysis</em>, Torrence &amp; Compo (1998)</a></p></li>
<li><p><a class="reference external" href="https://github.com/regeirk/pycwt">The <code class="docutils literal notranslate"><span class="pre">pycwt</span></code> Python package</a></p></li>
</ul>
<p>We will first download and extract the data, load it into a DataLoader, and then look at an example.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Download and extract training data</span>
<span class="c1"># Comment this cell out if you&#39;ve already downloaded and extracted the data once!</span>
<span class="o">!</span>curl<span class="w"> </span>-o<span class="w"> </span>hlsp_smarts_tess_ffi_all_tess_v1.0_cat.tar.gz<span class="w"> </span>https://archive.stsci.edu/hlsps/smarts/tess/hlsp_smarts_tess_ffi_all_tess_v1.0_cat.tar.gz
<span class="o">!</span>tar<span class="w"> </span>-xvzf<span class="w"> </span>hlsp_smarts_tess_ffi_all_tess_v1.0_cat.tar.gz
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed

  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  3 1873M    3 61.8M    0     0  67.0M      0  0:00:27 --:--:--  0:00:27 67.0M
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  6 1873M    6  114M    0     0  59.5M      0  0:00:31  0:00:01  0:00:30 59.5M
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  6 1873M    6  128M    0     0  43.8M      0  0:00:42  0:00:02  0:00:40 43.8M
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  7 1873M    7  134M    0     0  34.1M      0  0:00:54  0:00:03  0:00:51 34.1M
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  7 1873M    7  140M    0     0  28.3M      0  0:01:06  0:00:04  0:01:02 28.3M
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  7 1873M    7  145M    0     0  24.6M      0  0:01:16  0:00:05  0:01:11 16.7M
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  7 1873M    7  149M    0     0  21.5M      0  0:01:26  0:00:06  0:01:20 7214k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  8 1873M    8  152M    0     0  19.1M      0  0:01:37  0:00:07  0:01:30 4897k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  8 1873M    8  154M    0     0  17.3M      0  0:01:47  0:00:08  0:01:39 4276k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  8 1873M    8  158M    0     0  15.9M      0  0:01:57  0:00:09  0:01:48 3791k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  8 1873M    8  163M    0     0  14.9M      0  0:02:05  0:00:10  0:01:55 3609k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  8 1873M    8  167M    0     0  14.0M      0  0:02:13  0:00:11  0:02:02 3568k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  9 1873M    9  170M    0     0  13.1M      0  0:02:22  0:00:12  0:02:10 3695k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  9 1873M    9  173M    0     0  12.4M      0  0:02:30  0:00:13  0:02:17 3793k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  9 1873M    9  176M    0     0  11.8M      0  0:02:38  0:00:14  0:02:24 3745k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  9 1873M    9  180M    0     0  11.3M      0  0:02:45  0:00:15  0:02:30 3558k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  9 1873M    9  184M    0     0  10.8M      0  0:02:52  0:00:16  0:02:36 3482k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 10 1873M   10  187M    0     0  10.4M      0  0:02:59  0:00:17  0:02:42 3565k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 10 1873M   10  191M    0     0  10.1M      0  0:03:05  0:00:18  0:02:47 3709k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 10 1873M   10  194M    0     0   9.7M      0  0:03:11  0:00:19  0:02:52 3672k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 10 1873M   10  197M    0     0  9670k      0  0:03:18  0:00:20  0:02:58 3474k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 10 1873M   10  200M    0     0  9346k      0  0:03:25  0:00:21  0:03:04 3293k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 10 1873M   10  202M    0     0  9062k      0  0:03:31  0:00:22  0:03:09 3143k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 10 1873M   10  206M    0     0  8813k      0  0:03:37  0:00:23  0:03:14 2956k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 11 1873M   11  210M    0     0  8637k      0  0:03:42  0:00:24  0:03:18 3160k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 11 1873M   11  213M    0     0  8434k      0  0:03:47  0:00:25  0:03:22 3253k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 11 1873M   11  217M    0     0  8254k      0  0:03:52  0:00:26  0:03:26 3468k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 11 1873M   11  219M    0     0  8048k      0  0:03:58  0:00:27  0:03:31 3388k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 11 1873M   11  222M    0     0  7861k      0  0:04:04  0:00:28  0:03:36 3289k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 12 1873M   12  225M    0     0  7723k      0  0:04:08  0:00:29  0:03:39 3166k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 12 1873M   12  230M    0     0  7635k      0  0:04:11  0:00:30  0:03:41 3496k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 12 1873M   12  234M    0     0  7505k      0  0:04:15  0:00:31  0:03:44 3486k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 12 1873M   12  236M    0     0  7350k      0  0:04:21  0:00:32  0:03:49 3449k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 12 1873M   12  238M    0     0  7206k      0  0:04:26  0:00:33  0:03:53 3416k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 12 1873M   12  240M    0     0  7064k      0  0:04:31  0:00:34  0:03:57 3124k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 13 1873M   13  244M    0     0  6957k      0  0:04:35  0:00:35  0:04:00 2778k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 13 1873M   13  248M    0     0  6880k      0  0:04:38  0:00:36  0:04:02 2882k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 13 1873M   13  250M    0     0  6774k      0  0:04:43  0:00:37  0:04:06 2988k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 13 1873M   13  253M    0     0  6653k      0  0:04:48  0:00:38  0:04:10 2918k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 13 1873M   13  255M    0     0  6547k      0  0:04:53  0:00:39  0:04:14 2931k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 13 1873M   13  258M    0     0  6465k      0  0:04:56  0:00:40  0:04:16 2922k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 14 1873M   14  262M    0     0  6419k      0  0:04:58  0:00:41  0:04:17 3004k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 14 1873M   14  267M    0     0  6387k      0  0:05:00  0:00:42  0:04:18 3447k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 14 1873M   14  272M    0     0  6345k      0  0:05:02  0:00:43  0:04:19 3942k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 14 1873M   14  275M    0     0  6276k      0  0:05:05  0:00:44  0:04:21 4116k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 14 1873M   14  278M    0     0  6208k      0  0:05:09  0:00:45  0:04:24 4093k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 15 1873M   15  281M    0     0  6152k      0  0:05:11  0:00:46  0:04:25 3913k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 15 1873M   15  285M    0     0  6106k      0  0:05:14  0:00:47  0:04:27 3696k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 15 1873M   15  289M    0     0  6056k      0  0:05:16  0:00:48  0:04:28 3516k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 15 1873M   15  292M    0     0  6001k      0  0:05:19  0:00:49  0:04:30 3529k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 15 1873M   15  295M    0     0  5936k      0  0:05:23  0:00:50  0:04:33 3445k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 15 1873M   15  298M    0     0  5887k      0  0:05:25  0:00:51  0:04:34 3407k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 16 1873M   16  301M    0     0  5829k      0  0:05:29  0:00:52  0:04:37 3176k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 16 1873M   16  303M    0     0  5759k      0  0:05:33  0:00:53  0:04:40 2855k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 16 1873M   16  305M    0     0  5699k      0  0:05:36  0:00:54  0:04:42 2686k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 16 1873M   16  307M    0     0  5634k      0  0:05:40  0:00:55  0:04:45 2555k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 16 1873M   16  309M    0     0  5570k      0  0:05:44  0:00:56  0:04:48 2268k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 16 1873M   16  311M    0     0  5500k      0  0:05:48  0:00:57  0:04:51 2019k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 16 1873M   16  313M    0     0  5449k      0  0:05:52  0:00:58  0:04:54 2105k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 16 1873M   16  316M    0     0  5403k      0  0:05:55  0:00:59  0:04:56 2147k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 17 1873M   17  319M    0     0  5370k      0  0:05:57  0:01:00  0:04:57 2415k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 17 1873M   17  323M    0     0  5345k      0  0:05:58  0:01:01  0:04:57 2800k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 17 1873M   17  327M    0     0  5330k      0  0:05:59  0:01:02  0:04:57 3363k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 17 1873M   17  330M    0     0  5301k      0  0:06:01  0:01:03  0:04:58 3558k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 17 1873M   17  333M    0     0  5263k      0  0:06:04  0:01:04  0:05:00 3592k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 17 1873M   17  336M    0     0  5226k      0  0:06:07  0:01:05  0:05:02 3468k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 18 1873M   18  339M    0     0  5193k      0  0:06:09  0:01:06  0:05:03 3310k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 18 1873M   18  341M    0     0  5149k      0  0:06:12  0:01:07  0:05:05 2878k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 18 1873M   18  344M    0     0  5114k      0  0:06:15  0:01:08  0:05:07 2728k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 18 1873M   18  346M    0     0  5079k      0  0:06:17  0:01:09  0:05:08 2680k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 18 1873M   18  349M    0     0  5052k      0  0:06:19  0:01:10  0:05:09 2766k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 18 1873M   18  351M    0     0  5009k      0  0:06:23  0:01:11  0:05:12 2539k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 18 1873M   18  354M    0     0  4973k      0  0:06:25  0:01:12  0:05:13 2579k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 19 1873M   19  357M    0     0  4946k      0  0:06:27  0:01:13  0:05:14 2622k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 19 1873M   19  358M    0     0  4904k      0  0:06:31  0:01:14  0:05:17 2461k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 19 1873M   19  360M    0     0  4866k      0  0:06:34  0:01:15  0:05:19 2223k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 19 1873M   19  363M    0     0  4835k      0  0:06:36  0:01:16  0:05:20 2322k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 19 1873M   19  365M    0     0  4808k      0  0:06:39  0:01:17  0:05:22 2403k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 19 1873M   19  368M    0     0  4779k      0  0:06:41  0:01:18  0:05:23 2318k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 19 1873M   19  370M    0     0  4747k      0  0:06:44  0:01:19  0:05:25 2392k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 19 1873M   19  373M    0     0  4726k      0  0:06:45  0:01:20  0:05:25 2607k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 20 1873M   20  375M    0     0  4695k      0  0:06:48  0:01:21  0:05:27 2539k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 20 1873M   20  377M    0     0  4658k      0  0:06:51  0:01:22  0:05:29 2304k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 20 1873M   20  379M    0     0  4629k      0  0:06:54  0:01:23  0:05:31 2250k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 20 1873M   20  381M    0     0  4601k      0  0:06:57  0:01:24  0:05:33 2266k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 20 1873M   20  384M    0     0  4582k      0  0:06:58  0:01:25  0:05:33 2257k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 20 1873M   20  387M    0     0  4564k      0  0:07:00  0:01:26  0:05:34 2436k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 20 1873M   20  389M    0     0  4540k      0  0:07:02  0:01:27  0:05:35 2590k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 20 1873M   20  392M    0     0  4515k      0  0:07:04  0:01:28  0:05:36 2604k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 21 1873M   21  394M    0     0  4491k      0  0:07:07  0:01:29  0:05:38 2633k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 21 1873M   21  397M    0     0  4476k      0  0:07:08  0:01:30  0:05:38 2635k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 21 1873M   21  399M    0     0  4450k      0  0:07:11  0:01:31  0:05:40 2456k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 21 1873M   21  401M    0     0  4419k      0  0:07:14  0:01:32  0:05:42 2302k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 21 1873M   21  403M    0     0  4397k      0  0:07:16  0:01:33  0:05:43 2297k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 21 1873M   21  406M    0     0  4380k      0  0:07:18  0:01:34  0:05:44 2371k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 21 1873M   21  409M    0     0  4369k      0  0:07:19  0:01:35  0:05:44 2429k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 21 1873M   21  411M    0     0  4348k      0  0:07:21  0:01:36  0:05:45 2479k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 22 1873M   22  413M    0     0  4322k      0  0:07:23  0:01:37  0:05:46 2516k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 22 1873M   22  415M    0     0  4296k      0  0:07:26  0:01:38  0:05:48 2392k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 22 1873M   22  417M    0     0  4274k      0  0:07:28  0:01:39  0:05:49 2267k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 22 1873M   22  420M    0     0  4262k      0  0:07:30  0:01:40  0:05:50 2215k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 22 1873M   22  423M    0     0  4253k      0  0:07:31  0:01:41  0:05:50 2416k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 22 1873M   22  425M    0     0  4232k      0  0:07:33  0:01:42  0:05:51 2471k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 22 1873M   22  427M    0     0  4213k      0  0:07:35  0:01:43  0:05:52 2580k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 22 1873M   22  429M    0     0  4187k      0  0:07:38  0:01:44  0:05:54 2446k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 23 1873M   23  431M    0     0  4166k      0  0:07:40  0:01:45  0:05:55 2226k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 23 1873M   23  433M    0     0  4149k      0  0:07:42  0:01:46  0:05:56 2025k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 23 1873M   23  436M    0     0  4140k      0  0:07:43  0:01:47  0:05:56 2250k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 23 1873M   23  439M    0     0  4136k      0  0:07:43  0:01:48  0:05:55 2526k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 23 1873M   23  444M    0     0  4136k      0  0:07:43  0:01:49  0:05:54 3072k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 23 1873M   23  447M    0     0  4126k      0  0:07:45  0:01:50  0:05:55 3285k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 24 1873M   24  450M    0     0  4120k      0  0:07:45  0:01:51  0:05:54 3495k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 24 1873M   24  454M    0     0  4124k      0  0:07:45  0:01:52  0:05:53 3775k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 24 1873M   24  458M    0     0  4120k      0  0:07:45  0:01:53  0:05:52 3772k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 24 1873M   24  461M    0     0  4110k      0  0:07:46  0:01:54  0:05:52 3532k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 24 1873M   24  465M    0     0  4109k      0  0:07:46  0:01:55  0:05:51 3738k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 25 1873M   25  469M    0     0  4109k      0  0:07:46  0:01:56  0:05:50 3860k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 25 1873M   25  473M    0     0  4108k      0  0:07:47  0:01:57  0:05:50 3750k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 25 1873M   25  478M    0     0  4116k      0  0:07:46  0:01:58  0:05:48 4028k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 25 1873M   25  483M    0     0  4125k      0  0:07:45  0:01:59  0:05:46 4478k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 25 1873M   25  486M    0     0  4122k      0  0:07:45  0:02:00  0:05:45 4423k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 26 1873M   26  489M    0     0  4112k      0  0:07:46  0:02:01  0:05:45 4179k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 26 1873M   26  493M    0     0  4110k      0  0:07:46  0:02:02  0:05:44 4158k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 26 1873M   26  498M    0     0  4116k      0  0:07:46  0:02:03  0:05:43 4134k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 26 1873M   26  502M    0     0  4121k      0  0:07:45  0:02:04  0:05:41 4015k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 27 1873M   27  507M    0     0  4124k      0  0:07:45  0:02:05  0:05:40 4163k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 27 1873M   27  511M    0     0  4122k      0  0:07:45  0:02:06  0:05:39 4386k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 27 1873M   27  516M    0     0  4131k      0  0:07:44  0:02:07  0:05:37 4652k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 27 1873M   27  522M    0     0  4150k      0  0:07:42  0:02:08  0:05:34 4985k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 28 1873M   28  530M    0     0  4180k      0  0:07:39  0:02:09  0:05:30 5650k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 28 1873M   28  539M    0     0  4216k      0  0:07:35  0:02:10  0:05:25 6533k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 29 1873M   29  546M    0     0  4240k      0  0:07:32  0:02:11  0:05:21 7222k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 29 1873M   29  552M    0     0  4257k      0  0:07:30  0:02:12  0:05:18 7477k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 29 1873M   29  559M    0     0  4277k      0  0:07:28  0:02:13  0:05:15 7559k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 30 1873M   30  564M    0     0  4282k      0  0:07:28  0:02:14  0:05:14 6939k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 30 1873M   30  570M    0     0  4295k      0  0:07:26  0:02:15  0:05:11 6373k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 30 1873M   30  576M    0     0  4307k      0  0:07:25  0:02:16  0:05:09 6079k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 30 1873M   30  580M    0     0  4311k      0  0:07:25  0:02:17  0:05:08 5734k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 31 1873M   31  586M    0     0  4322k      0  0:07:23  0:02:18  0:05:05 5524k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 31 1873M   31  590
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>M    0     0  4324k      0  0:07:23  0:02:19  0:05:04 5475k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 31 1873M   31  595M    0     0  4328k      0  0:07:23  0:02:20  0:05:03 5211k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 32 1873M   32  600M    0     0  4331k      0  0:07:23  0:02:21  0:05:02 4974k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 32 1873M   32  605M    0     0  4335k      0  0:07:22  0:02:22  0:05:00 5006k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 32 1873M   32  610M    0     0  4340k      0  0:07:22  0:02:23  0:04:59 4834k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 32 1873M   32  616M    0     0  4353k      0  0:07:20  0:02:24  0:04:56 5152k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 33 1873M   33  623M    0     0  4375k      0  0:07:18  0:02:25  0:04:53 5702k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 33 1873M   33  629M    0     0  4388k      0  0:07:17  0:02:26  0:04:51 6012k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 33 1873M   33  634M    0     0  4394k      0  0:07:16  0:02:27  0:04:49 6090k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 34 1873M   34  638M    0     0  4386k      0  0:07:17  0:02:28  0:04:49 5714k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 34 1873M   34  640M    0     0  4377k      0  0:07:18  0:02:29  0:04:49 5058k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 34 1873M   34  643M    0     0  4364k      0  0:07:19  0:02:30  0:04:49 4037k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 34 1873M   34  646M    0     0  4356k      0  0:07:20  0:02:31  0:04:49 3436k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 34 1873M   34  650M    0     0  4358k      0  0:07:20  0:02:32  0:04:48 3273k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 35 1873M   35  655M    0     0  4363k      0  0:07:19  0:02:33  0:04:46 3686k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 35 1873M   35  659M    0     0  4357k      0  0:07:20  0:02:34  0:04:46 3775k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 35 1873M   35  662M    0     0  4352k      0  0:07:20  0:02:35  0:04:45 4016k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 35 1873M   35  666M    0     0  4350k      0  0:07:21  0:02:36  0:04:45 4146k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 35 1873M   35  670M    0     0  4348k      0  0:07:21  0:02:37  0:04:44 4051k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 35 1873M   35  674M    0     0  4343k      0  0:07:21  0:02:38  0:04:43 3720k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 36 1873M   36  677M    0     0  4338k      0  0:07:22  0:02:39  0:04:43 3743k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 36 1873M   36  681M    0     0  4337k      0  0:07:22  0:02:40  0:04:42 3856k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 36 1873M   36  685M    0     0  4332k      0  0:07:22  0:02:41  0:04:41 3767k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 36 1873M   36  688M    0     0  4330k      0  0:07:23  0:02:42  0:04:41 3750k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 36 1873M   36  691M    0     0  4317k      0  0:07:24  0:02:43  0:04:41 3495k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 37 1873M   37  693M    0     0  4305k      0  0:07:25  0:02:44  0:04:41 3246k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 37 1873M   37  696M    0     0  4296k      0  0:07:26  0:02:45  0:04:41 2972k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 37 1873M   37  700M    0     0  4294k      0  0:07:26  0:02:46  0:04:40 3087k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 37 1873M   37  703M    0     0  4292k      0  0:07:27  0:02:47  0:04:40 3062k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 37 1873M   37  708M    0     0  4297k      0  0:07:26  0:02:48  0:04:38 3619k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 38 1873M   38  714M    0     0  4308k      0  0:07:25  0:02:49  0:04:36 4415k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 38 1873M   38  719M    0     0  4312k      0  0:07:24  0:02:50  0:04:34 4846k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 38 1873M   38  724M    0     0  4316k      0  0:07:24  0:02:51  0:04:33 5027k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 38 1873M   38  730M    0     0  4327k      0  0:07:23  0:02:52  0:04:31 5516k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 39 1873M   39  735M    0     0  4330k      0  0:07:23  0:02:53  0:04:30 5465k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 39 1873M   39  739M    0     0  4329k      0  0:07:23  0:02:54  0:04:29 5051k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 39 1873M   39  743M    0     0  4329k      0  0:07:23  0:02:55  0:04:28 4901k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 39 1873M   39  747M    0     0  4326k      0  0:07:23  0:02:56  0:04:27 4679k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 40 1873M   40  751M    0     0  4324k      0  0:07:23  0:02:57  0:04:26 4230k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 40 1873M   40  755M    0     0  4322k      0  0:07:23  0:02:58  0:04:25 4053k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 40 1873M   40  758M    0     0  4314k      0  0:07:24  0:02:59  0:04:25 3779k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 40 1873M   40  761M    0     0  4308k      0  0:07:25  0:03:00  0:04:25 3566k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 40 1873M   40  764M    0     0  4303k      0  0:07:25  0:03:01  0:04:24 3506k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 40 1873M   40  767M    0     0  4298k      0  0:07:26  0:03:02  0:04:24 3356k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 41 1873M   41  770M    0     0  4292k      0  0:07:27  0:03:03  0:04:24 3203k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 41 1873M   41  773M    0     0  4282k      0  0:07:28  0:03:04  0:04:24 3146k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 41 1873M   41  776M    0     0  4278k      0  0:07:28  0:03:05  0:04:23 3207k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 41 1873M   41  780M    0     0  4273k      0  0:07:28  0:03:06  0:04:22 3177k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 41 1873M   41  784M    0     0  4274k      0  0:07:28  0:03:07  0:04:21 3394k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 41 1873M   41  786M    0     0  4265k      0  0:07:29  0:03:08  0:04:21 3260k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 42 1873M   42  790M    0     0  4260k      0  0:07:30  0:03:09  0:04:21 3420k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 42 1873M   42  794M    0     0  4261k      0  0:07:30  0:03:10  0:04:20 3646k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 42 1873M   42  799M    0     0  4263k      0  0:07:30  0:03:11  0:04:19 3867k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 42 1873M   42  802M    0     0  4257k      0  0:07:30  0:03:12  0:04:18 3631k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 42 1873M   42  805M    0     0  4252k      0  0:07:31  0:03:13  0:04:18 3772k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 43 1873M   43  808M    0     0  4248k      0  0:07:31  0:03:14  0:04:17 3787k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 43 1873M   43  812M    0     0  4246k      0  0:07:31  0:03:15  0:04:16 3646k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 43 1873M   43  816M    0     0  4248k      0  0:07:31  0:03:16  0:04:15 3668k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 43 1873M   43  821M    0     0  4250k      0  0:07:31  0:03:17  0:04:14 3952k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 44 1873M   44  827M    0     0  4258k      0  0:07:30  0:03:18  0:04:12 4499k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 44 1873M   44  833M    0     0  4271k      0  0:07:29  0:03:19  0:04:10 5180k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 44 1873M   44  839M    0     0  4279k      0  0:07:28  0:03:20  0:04:08 5567k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 45 1873M   45  845M    0     0  4286k      0  0:07:27  0:03:21  0:04:06 5792k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 45 1873M   45  851M    0     0  4295k      0  0:07:26  0:03:22  0:04:04 6096k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 45 1873M   45  856M    0     0  4300k      0  0:07:26  0:03:23  0:04:03 5975k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 45 1873M   45  861M    0     0  4303k      0  0:07:25  0:03:24  0:04:01 5581k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 46 1873M   46  864M    0     0  4300k      0  0:07:26  0:03:25  0:04:01 5176k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 46 1873M   46  868M    0     0  4299k      0  0:07:26  0:03:26  0:04:00 4838k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 46 1873M   46  874M    0     0  4305k      0  0:07:25  0:03:27  0:03:58 4704k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 46 1873M   46  880M    0     0  4315k      0  0:07:24  0:03:28  0:03:56 4931k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 47 1873M   47  887M    0     0  4330k      0  0:07:23  0:03:29  0:03:54 5438k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 47 1873M   47  893M    0     0  4335k      0  0:07:22  0:03:30  0:03:52 5753k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 47 1873M   47  898M    0   
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  0  4343k      0  0:07:21  0:03:31  0:03:50 6134k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 48 1873M   48  904M    0     0  4348k      0  0:07:21  0:03:32  0:03:49 6130k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 48 1873M   48  908M    0     0  4350k      0  0:07:21  0:03:33  0:03:48 5809k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 48 1873M   48  913M    0     0  4351k      0  0:07:20  0:03:34  0:03:46 5239k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 49 1873M   49  918M    0     0  4357k      0  0:07:20  0:03:35  0:03:45 5270k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 49 1873M   49  925M    0     0  4367k      0  0:07:19  0:03:36  0:03:43 5410k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 49 1873M   49  933M    0     0  4384k      0  0:07:17  0:03:37  0:03:40 5945k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 50 1873M   50  941M    0     0  4401k      0  0:07:15  0:03:38  0:03:37 6585k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 50 1873M   50  946M    0     0  4407k      0  0:07:15  0:03:39  0:03:36 6801k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 50 1873M   50  950M    0     0
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  4405k      0  0:07:15  0:03:40  0:03:35 6514k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 50 1873M   50  955M    0     0  4407k      0  0:07:15  0:03:41  0:03:34 6155k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 51 1873M   51  959M    0     0  4408k      0  0:07:15  0:03:42  0:03:33 5421k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 51 1873M   51  965M    0     0  4413k      0  0:07:14  0:03:43  0:03:31 4942k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 51 1873M   51  970M    0     0  4417k      0  0:07:14  0:03:44  0:03:30 4885k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 52 1873M   52  975M    0     0  4421k      0  0:07:14  0:03:45  0:03:29 5088k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 52 1873M   52  980M    0     0  4426k      0  0:07:13  0:03:46  0:03:27 5230k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 52 1873M   52  985M    0     0  4429k      0  0:07:13  0:03:47  0:03:26 5372k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 52 1873M   52  990M    0     0  4431k      0  0:07:13  0:03:48  0:03:25 5212k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 53 1873M   53  996M    0     0  4436k      0  0:07:12  0:03:49  0:03:23 5296k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 53 1873M   53 1001M    0     0  4439k      0  0:07:12  0:03:50  0:03:22 5263k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 53 1873M   53 1006M    0     0  4445k      0  0:07:11  0:03:51  0:03:20 5323k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 53 1873M   53 1010M    0     0  4443k      0  0:07:11  0:03:52  0:03:19 5104k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 54 1873M   54 1014M    0     0  4441k      0  0:07:12  0:03:53  0:03:19 4894k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 54 1873M   54 1019M    0     0  4443k      0  0:07:11  0:03:54  0:03:17 4750k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 54 1873M   54 1023M    0     0  4440k      0  0:07:12  0:03:55  0:03:17 4509k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 54 1873M   54 1027M    0     0  4441k      0  0:07:12  0:03:56  0:03:16 4239k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 55 1873M   55 1033M    0     0  4447k      0  0:07:11  0:03:57  0:03:14 4611k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 55 1873M   55 1040M    0     0  4458k      0  0:07:10  0:03:58  0:03:12 5274k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 55 1873M   55 1045M    0     0  4462k      0  0:07:09  0:03:59  0:03:10 5370k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 56 1873M   56 1050M    0     0  4463k      0  0:07:09  0:04:00  0:03:09 5541k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 56 1873M   56 1054M    0     0  4465k      0  0:07:09  0:04:01  0:03:08 5627k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 56 1873M   56 1061M    0     0  4472k      0  0:07:09  0:04:02  0:03:07 5677k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 57 1873M   57 1068M    0     0  4484k      0  0:07:07  0:04:03  0:03:04 5705k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 57 1873M   57 1076M    0     0  4501k      0  0:07:06  0:04:04  0:03:02 6371k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 57 1873M   57 1084M    0     0  4514k      0  0:07:05  0:04:05  0:03:00 6946k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 58 1873M   58 1092M    0     0  4530k      0  0:07:03  0:04:06  0:02:57 7658k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 58 1873M   58 1097M    0     0  4532k      0  0:07:03  0:04:07  0:02:56 7453k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 58 1873M   58 1102M    0     0  4536k      0  0:07:03  0:04:08  0:02:55 7072k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 59 1873M   59 1108M    0     0  4542k      0  0:07:02  0:04:09  0:02:53 6513k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 59 1873M   59 1113M    0     0  4545k      0  0:07:02  0:04:10  0:02:52 6065k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 59 1873M   59 1119M    0     0  4549k      0  0:07:01  0:04:11  0:02:50 5506k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 60 1873M   60 1125M    0     0  4554k      0  0:07:01  0:04:12  0:02:49 5656k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 60 1873M   60 1131M    0     0  4561k      0  0:07:00  0:04:13  0:02:47 5792k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 60 1873M   60 1136M    0     0  4567k      0  0:07:00  0:04:14  0:02:46 5819k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 60 1873M   60 1142M    0     0  4569k      0  0:06:59  0:04:15  0:02:44 5795k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 61 1873M   61 1146M    0     0  4567k      0  0:07:00  0:04:16  0:02:44 5466k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 61 1873M   61 1150M    0     0  4567k      0  0:07:00  0:04:17  0:02:43 5223k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 61 1873M   61 1156M    0     0  4573k      0  0:06:59  0:04:18  0:02:41 5184k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 62 1873M   62 1163M    0     0  4584k      0  0:06:58  0:04:19  0:02:39 5446k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 62 1873M   62 1171M    0     0  4599k      0  0:06:57  0:04:20  0:02:37 6136k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 63 1873M   63 1181M    0     0  4619k      0  0:06:55  0:04:21  0:02:34 7284k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 63 1873M   63 1190M    0     0  4635k      0  0:06:53  0:04:22  0:02:31 8109k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 64 1873M   64 1199M    0     0  4654k      0  0:06:52  0:04:23  0:02:29 8893k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 64 1873M   64 1210M    0     0  4677k      0  0:06:50  0:04:24  0:02:26 9541k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 65 1873M   65 1221M    0     0  4703k      0  0:06:47  0:04:25  0:02:22  9.9M
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 65 1873M   65 1231M    0     0  4724k      0  0:06:46  0:04:26  0:02:20  9.9M
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 66 1873M   66 1242M    0     0  4748k      0  0:06:44  0:04:27  0:02:17 10.4M
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 66 1873M   66 1249M    0     0  4755k      0  0:06:43  0:04:28  0:02:15  9.8M
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 67 1873M   67 1255M    0     0  4763k      0  0:06:42  0:04:29  0:02:13 9332k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 67 1873M   67 1260M    0     0  4763k      0  0:06:42  0:04:30  0:02:12 7945k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 67 1873M   67 1263M    0     0  4758k      0  0:06:43  0:04:31  0:02:12 6590k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 67 1873M   67 1268M    0     0  4757k      0  0:06:43  0:04:32  0:02:11 5238k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 67 1873M   67 1274M    0     0  4762k      0  0:06:42  0:04:33  0:02:09 5126k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 68 1873M   68 1280M    0 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    0  4771k      0  0:06:42  0:04:34  0:02:08 5161k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 68 1873M   68 1286
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>M    0     0  4774k      0  0:06:41  0:04:35  0:02:06 5339k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 68 1873M   68 1290M    0     0  4771k      0  0:06:42  0:04:36  0:02:06 5506k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 69 1873M   69 1294M    0     0  4768k      0  0:06:42  0:04:37  0:02:05 5369k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 69 1873M   69 1298M    0     0  4766k      0  0:06:42  0:04:38  0:02:04 5004k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 69 1873M   69 1302M    0     0  4765k      0  0:06:42  0:04:39  0:02:03 4471k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 69 1873M   69 1307M    0     0  4764k      0  0:06:42  0:04:40  0:02:02 4222k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 69 1873M   69 1311M    0     0  4761k      0  0:06:42  0:04:41  0:02:01 4209k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 70 1873M   70 1315M    0     0  4762k      0  0:06:42  0:04:42  0:02:00 4424k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 70 1873M   70 1321M    0     0  4767k      0  0:06:42  0:04:43  0:01:59 4768k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 70 1873M   70 1328M    0     0  4774k      0  0:06:41  0:04:44  0:01:57 5271k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 71 1873M   71 1332M    0     0  4773k      0  0:06:41  0:04:45  0:01:56 5284k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 71 1873M   71 1338M    0     0  4777k      0  0:06:41  0:04:46  0:01:55 5649k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 71 1873M   71 1344M    0     0  4781k      0  0:06:41  0:04:47  0:01:54 5860k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 71 1873M   71 1348M    0     0  4779k      0  0:06:41  0:04:48  0:01:53 5478k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 72 1873M   72 1352M    0     0  4777k      0  0:06:41  0:04:49  0:01:52 4937k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 72 1873M   72 1357M    0     0  4777k      0  0:06:41  0:04:50  0:01:51 5026k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 72 1873M   72 1362M    0     0  4779k      0  0:06:41  0:04:51  0:01:50 4888k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 73 1873M   73 1368M    0     0  4784k      0  0:06:41  0:04:52  0:01:49 4946k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 73 1873M   73 1374M    0     0  4787k      0  0:06:40  0:04:53  0:01:47 5270k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 73 1873M   73 1380M    0     0  4794k      0  0:06:40  0:04:54  0:01:46 5777k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 73 1873M   73 1385M    0     0  4795k      0  0:06:40  0:04:55  0:01:45 5853k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 74 1873M   74 1390M    0     0  4793k      0  0:06:40  0:04:56  0:01:44 5635k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 74 1873M   74 1392M    0     0  4785k      0  0:06:40  0:04:57  0:01:43 4880k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 74 1873M   74 1395M    0     0  4779k      0  0:06:41  0:04:58  0:01:43 4279k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 74 1873M   74 1398M    0     0  4773k      0  0:06:41  0:04:59  0:01:42 3545k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 74 1873M   74 1401M    0     0  4768k      0  0:06:42  0:05:00  0:01:42 3150k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 74 1873M   74 1404M    0     0  4764k      0  0:06:42  0:05:01  0:01:41 3017k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 75 1873M   75 1408M    0     0  4762k      0  0:06:42  0:05:02  0:01:40 3358k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 75 1873M   75 1414M    0     0  4764k      0  0:06:42  0:05:03  0:01:39 3914k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 75 1873M   75 1419M    0     0  4765k      0  0:06:42  0:05:04  0:01:38 4271k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 76 1873M   76 1424M    0     0  4769k      0  0:06:42  0:05:05  0:01:37 4821k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 76 1873M   76 1431M    0     0  4776k      0  0:06:41  0:05:06  0:01:35 5528k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 76 1873M   76 1437M    0     0  4780k      0  0:06:41  0:05:07  0:01:34 5904k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 76 1873M   76 1442M    0     0  4780k      0  0:06:41  0:05:08  0:01:33 5723k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 77 1873M   77 1446M    0     0  4780k      0  0:06:41  0:05:09  0:01:32 5700k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 77 1873M   77 1452M    0     0  4784k      0  0:06:41  0:05:10  0:01:31 5689k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 77 1873M   77 1457M    0     0  4785k      0  0:06:40  0:05:11  0:01:29 5323k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 78 1873M   78 1462M    0     0  4785k      0  0:06:40  0:05:12  0:01:28 5089k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 78 1873M   78 1468M    0     0  4790k      0  0:06:40  0:05:13  0:01:27 5379k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 78 1873M   78 1473M    0     0  4791k      0  0:06:40  0:05:14  0:01:26 5485k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 78 1873M   78 1477M    0     0  4788k      0  0:06:40  0:05:15  0:01:25 5040k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 79 1873M   79 1481M    0     0  4786k      0  0:06:40  0:05:16  0:01:24 4834k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 79 1873M   79 1485M    0     0  4782k      0  0:06:41  0:05:17  0:01:24 4592k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 79 1873M   79 1488M    0     0  4780k      0  0:06:41  0:05:18  0:01:23 4195k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 79 1873M   79 1493M    0     0  4780k      0  0:06:41  0:05:19  0:01:22 4068k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 79 1873M   79 1497M    0     0  4777k      0  0:06:41  0:05:20  0:01:21 4090k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 80 1873M   80 1500M    0     0  4774k      0  0:06:41  0:05:21  0:01:20 4028k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 80 1873M   80 1504M    0     0  4770k      0  0:06:42  0:05:22  0:01:20 3987k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 80 1873M   80 1507M    0     0  4766k      0  0:06:42  0:05:23  0:01:19 3850k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 80 1873M   80 1511M    0     0  4763k      0  0:06:42  0:05:24  0:01:18 3665k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 80 1873M   80 1515M    0     0  4762k      0  0:06:42  0:05:25  0:01:17 3783k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 81 1873M   81 1521M    0     0  4765k      0  0:06:42  0:05:26  0:01:16 4181k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 81 1873M   81 1526M    0     0  4766k      0  0:06:42  0:05:27  0:01:15 4504k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 81 1873M   81 1532M    0     0  4770k      0  0:06:42  0:05:28  0:01:14 5046k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 82 1873M   82 1537M    0     0  4771k      0  0:06:42  0:05:29  0:01:13 5330k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 82 1873M   82 1542M    0     0  4772k      0  0:06:42  0:05:30  0:01:12 5430k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 82 1873M   82 1548M    0     0  4775k      0  0:06:41  0:05:31  0:01:10 5469k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 82 1873M   82 1555M    0     0  4782k      0  0:06:41  0:05:32  0:01:09 5848k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 83 1873M   83 1559M    0     0  4782k      0  0:06:41  0:05:33  0:01:08 5583k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 83 1873M   83 1565M    0     0  4785k      0  0:06:40  0:05:34  0:01:06 5681k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 83 1873M   83 1569M    0     0  4785k      0  0:06:40  0:05:35  0:01:05 5650k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 84 1873M   84 1574M    0     0  4785k      0  0:06:41  0:05:36  0:01:05 5384k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 84 1873M   84 1580M    0     0  4788k      0  0:06:40  0:05:37  0:01:03 5161k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 84 1873M   84 1587M    0     0  4795k      0  0:06:40  0:05:38  0:01:02 5673k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 85 1873M   85 1593M    0     0  4800k      0  0:06:39  0:05:39  0:01:00 5844k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 85 1873M   85 1600M    0     0  4807k      0  0:06:39  0:05:40  0:00:59 6298k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 85 1873M   85 1607M    0     0  4814k      0  0:06:38  0:05:41  0:00:57 6795k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 85 1873M   85 1611M    0     0  4811k      0  0:06:38  0:05:42  0:00:56 6392k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 86 1873M   86 1615M    0     0  4808k      0  0:06:39  0:05:43  0:00:56 5663k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 86 1873M   86 1618M    0     0  4805k      0  0:06:39  0:05:44  0:00:55 5124k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 86 1873M   86 1622M    0     0  4802k      0  0:06:39  0:05:45  0:00:54 4449k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 86 1873M   86 1625M    0     0  4796k      0  0:06:40  0:05:46  0:00:54 3563k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 86 1873M   86 1627M    0     0  4789k      0  0:06:40  0:05:47  0:00:53 3237k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 86 1873M   86 1630M    0     0  4783k      0  0:06:41  0:05:48  0:00:53 3079k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 87 1873M   87 1634M    0     0  4781k      0  0:06:41  0:05:49  0:00:52 3145k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 87 1873M   87 1637M    0     0  4779k      0  0:06:41  0:05:50  0:00:51 3205k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 87 1873M   87 1641M    0     0  4776k      0  0:06:41  0:05:51  0:00:50 3410k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 87 1873M   87 1646M    0     0  4777k      0  0:06:41  0:05:52  0:00:49 3941k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 88 1873M   88 1651M    0     0  4778k      0  0:06:41  0:05:53  0:00:48 4422k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 88 1873M   88 1655M    0     0  4776k      0  0:06:41  0:05:54  0:00:47 4386k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 88 1873M   88 1658M    0     0  4772k      0  0:06:42  0:05:55  0:00:47 4272k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 88 1873M   88 1661M    0     0  4766k      0  0:06:42  0:05:56  0:00:46 4045k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 88 1873M   88 1664M    0     0  4761k      0  0:06:43  0:05:57  0:00:46 3649k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 88 1873M   88 1667M    0     0  4757k      0  0:06:43  0:05:58  0:00:45 3246k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 89 1873M   89 1671M    0     0  4754k      0  0:06:43  0:05:59  0:00:44 3182k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 89 1873M   89 1674M    0     0  4751k      0  0:06:43  0:06:00  0:00:43 3296k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 89 1873M   89 1678M    0     0  4748k      0  0:06:44  0:06:01  0:00:43 3490k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 89 1873M   89 1681M    0     0  4745k      0  0:06:44  0:06:02  0:00:42 3617k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 89 1873M   89 1686M    0     0  4745k      0  0:06:44  0:06:03  0:00:41 3873k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 90 1873M   90 1691M    0     0  4745k      0  0:06:44  0:06:04  0:00:40 4136k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 90 1873M   90 1695M    0     0  4744k      0  0:06:44  0:06:05  0:00:39 4171k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 90 1873M   90 1700M    0     0  4744k      0  0:06:44  0:06:06  0:00:38 4423k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 90 1873M   90 1704M    0     0  4743k      0  0:06:44  0:06:07  0:00:37 4611k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 91 1873M   91 1709M    0     0  4744k      0  0:06:44  0:06:08  0:00:36 4668k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 91 1873M   91 1713M    0     0  4743k      0  0:06:44  0:06:09  0:00:35 4609k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 91 1873M   91 1717M    0     0  4740k      0  0:06:44  0:06:10  0:00:34 4477k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 91 1873M   91 1720M    0     0  4737k      0  0:06:45  0:06:11  0:00:34 4199k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 91 1873M   91 1723M    0     0  4733k      0  0:06:45  0:06:12  0:00:33 3970k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 92 1873M   92 1727M    0     0  4730k      0  0:06:45  0:06:13  0:00:32 3747k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 92 1873M   92 1731M    0     0  4728k      0  0:06:45  0:06:14  0:00:31 3558k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 92 1873M   92 1733M    0     0  4722k      0  0:06:46  0:06:15  0:00:31 3368k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 92 1873M   92 1736M    0     0  4716k      0  0:06:46  0:06:16  0:00:30 3196k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 92 1873M   92 1738M    0     0  4711k      0  0:06:47  0:06:17  0:00:30 3054k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 92 1873M   92 1742M    0     0  4708k      0  0:06:47  0:06:18  0:00:29 3071k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 93 1873M   93 1746M    0     0  4708k      0  0:06:47  0:06:19  0:00:28 3217k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 93 1873M   93 1751M    0     0  4707k      0  0:06:47  0:06:20  0:00:27 3627k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 93 1873M   93 1754M    0     0  4704k      0  0:06:47  0:06:21  0:00:26 3803k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 93 1873M   93 1758M    0     0  4702k      0  0:06:48  0:06:22  0:00:26 4058k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 94 1873M   94 1762M    0     0  4700k      0  0:06:48  0:06:23  0:00:25 4069k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 94 1873M   94 1765M    0     0  4696k      0  0:06:48  0:06:24  0:00:24 3779k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 94 1873M   94 1767M    0     0  4690k      0  0:06:49  0:06:25  0:00:24 3347k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 94 1873M   94 1770M    0     0  4684k      0  0:06:49  0:06:26  0:00:23 3171k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 94 1873M   94 1773M    0     0  4681k      0  0:06:49  0:06:27  0:00:22 3060k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 94 1873M   94 1778M    0     0  4681k      0  0:06:49  0:06:28  0:00:21 3215k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 95 1873M   95 1780M    0     0  4676k      0  0:06:50  0:06:29  0:00:21 3153k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 95 1873M   95 1782M    0     0  4669k      0  0:06:50  0:06:30  0:00:20 3073k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 95 1873M   95 1784M    0     0  4663k      0  0:06:51  0:06:31  0:00:20 2990k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 95 1873M   95 1788M    0     0  4659k      0  0:06:51  0:06:32  0:00:19 2970k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 95 1873M   95 1792M    0     0  4659k      0  0:06:51  0:06:33  0:00:18 2913k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 95 1873M   95 1796M    0     0  4657k      0  0:06:52  0:06:34  0:00:18 3150k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 95 1873M   95 1798M    0     0  4652k      0  0:06:52  0:06:35  0:00:17 3303k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 96 1873M   96 1801M    0     0  4648k      0  0:06:52  0:06:36  0:00:16 3477k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 96 1873M   96 1805M    0     0  4646k      0  0:06:52  0:06:37  0:00:15 3591k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 96 1873M   96 1807M    0     0  4640k      0  0:06:53  0:06:38  0:00:15 3204k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 96 1873M   96 1810M    0     0  4635k      0  0:06:53  0:06:39  0:00:14 2952k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 96 1873M   96 1814M    0     0  4633k      0  0:06:54  0:06:40  0:00:14 3143k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 97 1873M   97 1818M    0     0  4632k      0  0:06:54  0:06:41  0:00:13 3348k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 97 1873M   97 1821M    0     0  4629k      0  0:06:54  0:06:42  0:00:12 3305k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 97 1873M   97 1825M    0     0  4626k      0  0:06:54  0:06:43  0:00:11 3488k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 97 1873M   97 1828M    0     0  4623k      0  0:06:54  0:06:44  0:00:10 3686k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 97 1873M   97 1832M    0     0  4623k      0  0:06:55  0:06:45  0:00:10 3829k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 98 1873M   98 1836M    0     0  4622k      0  0:06:55  0:06:46  0:00:09 3833k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 98 1873M   98 1839M    0
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     0  4617k      0  0:06:55  0:06:47  0:00:08 3647k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 98 1873M   98 1841M    0     0  4611k      0  0:06:56  0:06:48  0:00:08 3407k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 98 1873M   98 1844M    0     0  4607k      0  0:06:56  0:06:49  0:00:07 3232k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 98 1873M   98 1846M    0     0  4602k      0  0:06:56  0:06:50  0:00:06 2871k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 98 1873M   98 1849M    0     0  4597k      0  0:06:57  0:06:51  0:00:06 2605k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 98 1873M   98 1851M    0     0  4592k      0  0:06:57  0:06:52  0:00:05 2517k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 98 1873M   98 1854M    0     0  4588k      0  0:06:58  0:06:53  0:00:05 2689k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 99 1873M   99 1858M    0     0  4586k      0  0:06:58  0:06:54  0:00:04 2886k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 99 1873M   99 1862M    0     0  4584k      0  0:06:58  0:06:55  0:00:03 3099k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 99 1873M   99 1865M    0     0  4580k      0  0:06:58  0:06:56  0:00:02 3180k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 99 1873M   99 1868M    0     0  4578k      0  0:06:59  0:06:57  0:00:02 3417k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 99 1873M   99 1872M    0     0  4576k      0  0:06:59  0:06:58  0:00:01 3625k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100 1873M  100 1873M    0     0  4575k      0  0:06:59  0:06:59 --:--:-- 3606k
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>hlsp_smarts_tess_ffi_all_tess_v1.0_sim.fits
</pre></div>
</div>
</div>
</div>
<p>We will partition the data into three sets: a training, validation, and test set.</p>
<ul class="simple">
<li><p>The training set is used to fit the CNN parameters</p></li>
<li><p>The validation set is held-out for use to determine when to stop training. The training loss will decrease indefinitely, but the validation loss will stop decreasing when the CNN begins to overfit, signalling that it’s reached a local maximum in its ability to generalize to new data.</p></li>
<li><p>The test set is used for the final performance evaluation.</p></li>
</ul>
<p>We use Pytorch <code class="docutils literal notranslate"><span class="pre">Dataset</span></code> (subclassed here) and <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code> (used below) to load the wavelet data. Pytorch <code class="docutils literal notranslate"><span class="pre">Dataset</span></code> and <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code> can be accessed in batches, which makes training more efficient.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define Dataset and Dataloader classes</span>
<span class="k">class</span><span class="w"> </span><span class="nc">WaveletDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    WaveletDataset to read in the training data.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    periods: array of rotation period corresponding to each wavelet transform.</span>

<span class="sd">    wavelets: array containing the stack of wavelet transforms.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">periods</span><span class="p">,</span> <span class="n">wavelets</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="n">random_seed</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">max_n</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        `periods` (numpy.ndarray): the array of rotation periods, or labels.</span>

<span class="sd">        `wavelets` (numpy.ndarray): the array of wavelet power spectra, or features.</span>

<span class="sd">        `mode` (str): must be one of &quot;train&quot;, &quot;validation&quot;, or &quot;test&quot;. Loads different data</span>
<span class="sd">            depending on the specified mode.</span>

<span class="sd">        `random_seed` (int, optional): seed for random number generator for </span>
<span class="sd">            reproducibility.</span>

<span class="sd">        `max_n` (int, optional): the number of training examples to use.</span>

<span class="sd">        `split` (list-like): the split fractions for train/validation/test partitions</span>

<span class="sd">        `normalize` (bool): whether to divide the periods and wavelets by their maximum values.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># create shuffled index and shuffle arrays</span>
        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">random_seed</span><span class="p">)</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">periods</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">),</span> <span class="n">size</span><span class="o">=</span><span class="n">max_n</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">periods</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
        <span class="n">w</span> <span class="o">=</span> <span class="n">wavelets</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">normalize</span><span class="p">:</span>
            <span class="n">pmax</span> <span class="o">=</span> <span class="n">periods</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="n">wmax</span> <span class="o">=</span> <span class="n">wavelets</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="n">p</span> <span class="o">=</span> <span class="p">(</span><span class="n">p</span><span class="o">/</span><span class="n">pmax</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
            <span class="n">w</span> <span class="o">=</span> <span class="p">(</span><span class="n">w</span><span class="o">/</span><span class="n">wmax</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">pmax</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
            <span class="n">wmax</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
            <span class="n">p</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
            <span class="n">w</span> <span class="o">=</span> <span class="n">w</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pmax</span> <span class="o">=</span> <span class="n">pmax</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">wmax</span> <span class="o">=</span> <span class="n">wmax</span>

        <span class="c1"># determine how many examples to use for each partition</span>
        <span class="n">n_train</span><span class="p">,</span> <span class="n">n_val</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="p">(</span><span class="n">max_n</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">split</span><span class="p">)</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">split</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span><span class="o">.</span><span class="n">cumsum</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;train&quot;</span><span class="p">:</span>
            <span class="n">p</span> <span class="o">=</span> <span class="n">p</span><span class="p">[:</span><span class="n">n_train</span><span class="p">]</span>
            <span class="n">w</span> <span class="o">=</span> <span class="n">w</span><span class="p">[:</span><span class="n">n_train</span><span class="p">]</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;validation&quot;</span><span class="p">:</span>
            <span class="n">p</span> <span class="o">=</span> <span class="n">p</span><span class="p">[</span><span class="n">n_train</span><span class="p">:</span><span class="n">n_val</span><span class="p">]</span>
            <span class="n">w</span> <span class="o">=</span> <span class="n">w</span><span class="p">[</span><span class="n">n_train</span><span class="p">:</span><span class="n">n_val</span><span class="p">]</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;test&quot;</span><span class="p">:</span>
            <span class="n">p</span> <span class="o">=</span> <span class="n">p</span><span class="p">[</span><span class="n">n_val</span><span class="p">:]</span>
            <span class="n">w</span> <span class="o">=</span> <span class="n">w</span><span class="p">[</span><span class="n">n_val</span><span class="p">:]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;`mode` must be one of &#39;train&#39;, &#39;validation&#39;, or &#39;test&#39;.&quot;</span><span class="p">)</span>

        <span class="c1"># Assign periods and wavelets to class attributes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">wavelets</span> <span class="o">=</span> <span class="n">w</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">periods</span> <span class="o">=</span> <span class="n">p</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns the number of training examples in the Dataset.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">periods</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The data accessor.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        `idx` (list-like): the list of indices to be accessed</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        `X` (tensor): substack of wavelet transforms</span>

<span class="sd">        `label` (tensor): sub-array of rotation periods</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">idx</span><span class="p">):</span>
            <span class="n">idx</span> <span class="o">=</span> <span class="n">idx</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">wavelets</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">label</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">periods</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">label</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Read SMARTS data into data loaders</span>
<span class="n">filename</span> <span class="o">=</span> <span class="s2">&quot;hlsp_smarts_tess_ffi_all_tess_v1.0_sim.fits&quot;</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Reading data from </span><span class="si">{</span><span class="n">filename</span><span class="si">}</span><span class="s2">...&quot;</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">)</span>

<span class="k">with</span> <span class="n">fits</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">memmap</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">f</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;Period&quot;</span><span class="p">]</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">f</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">data</span>
    <span class="n">train_dataset</span> <span class="o">=</span> <span class="n">WaveletDataset</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="p">,</span> <span class="n">max_n</span><span class="o">=</span><span class="n">max_n</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="n">split</span><span class="p">)</span>
    <span class="n">valid_dataset</span> <span class="o">=</span> <span class="n">WaveletDataset</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span> <span class="n">max_n</span><span class="o">=</span><span class="n">max_n</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="n">split</span><span class="p">)</span>
    <span class="n">test_dataset</span> <span class="o">=</span> <span class="n">WaveletDataset</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;test&quot;</span><span class="p">,</span> <span class="n">max_n</span><span class="o">=</span><span class="n">max_n</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="n">split</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Done.&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Storing training data into DataLoaders...&quot;</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
<span class="n">valid_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">valid_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Done.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Reading data from hlsp_smarts_tess_ffi_all_tess_v1.0_sim.fits...
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done.
Storing training data into DataLoaders...Done.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plot an example WPS</span>
<span class="n">wl</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="p">[</span><span class="mi">8</span><span class="p">]</span>

<span class="n">wldata</span> <span class="o">=</span> <span class="n">wl</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">pcolormesh</span><span class="p">(</span>
    <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">360</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">wldata</span><span class="p">)),</span>  <span class="c1"># time baseline is about a year</span>
    <span class="n">np</span><span class="o">.</span><span class="n">geomspace</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mi">180</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">wldata</span><span class="p">)),</span>  <span class="c1"># period axis goes from 0.1 to 180</span>
    <span class="n">wldata</span><span class="p">,</span>
    <span class="n">shading</span><span class="o">=</span><span class="s2">&quot;nearest&quot;</span><span class="p">,</span>
    <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;binary_r&quot;</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yscale</span><span class="p">(</span><span class="s2">&quot;log&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Time (days)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Period (days)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;SMARTS Wavelet Power Spectrum&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;Normalized Power&quot;</span><span class="p">)</span>

<span class="c1"># Plot the actual rotation period of the simulated star</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="mi">180</span><span class="o">*</span><span class="n">p</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;r&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;:&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/52e8f8f571227e2de1f8e80350b8278099e27aadacb87ee19bd9b5d94b46cda7.png" src="../../../_images/52e8f8f571227e2de1f8e80350b8278099e27aadacb87ee19bd9b5d94b46cda7.png" />
</div>
</div>
<p>This is an example of a WPS. For sinusoidal signals, there is a horizontal band of power at the dominant frequency. This example star has an equatorial rotation period of about 9 days, but the dominant frequency from the power spectrum is about 10.5 days. This is due to surface differential rotation, where spots emerge at higher latitudes that rotate more slowly than the equator.</p>
<p>This panel (without the axes or colorbar) is what the CNN will be trained on.</p>
</section>
<section id="build-the-cnn">
<h2>2. Build the CNN<a class="headerlink" href="#build-the-cnn" title="Permalink to this heading">#</a></h2>
<p>We will build a CNN that takes 2D input (the WPS) and predicts two values: the stellar rotation period and its corresponding uncertainty. The CNN has the following aspects:</p>
<ul class="simple">
<li><p>Three 2D convolution layers for feature extraction</p></li>
<li><p>ReLU activation</p></li>
<li><p>1D max pooling in the time axis, for dimensionality reduction without losing frequency resolution.</p></li>
<li><p>Dropout to build redundancy and avoid overfitting</p></li>
<li><p>Softplus output for regression</p></li>
</ul>
<p>The CNN also has a configurable number of feature extractors (also called “kernels” or “filters”), which is set by the <code class="docutils literal notranslate"><span class="pre">c</span></code> parameter. It defaults to <code class="docutils literal notranslate"><span class="pre">[8,</span> <span class="pre">16,</span> <span class="pre">32]</span></code>, so that each successive convolution layer increases in depth by a factor of 2. You might also try <code class="docutils literal notranslate"><span class="pre">[16,</span> <span class="pre">32,</span> <span class="pre">64]</span></code> or <code class="docutils literal notranslate"><span class="pre">[32,</span> <span class="pre">64,</span> <span class="pre">128]</span></code> to see whether more feature extractors improve the performance.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">ConvNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A relatively simple 2D Convolutional Neural Network with a configurable</span>
<span class="sd">    number of trainable convolution kernels.</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    c (list of ints, [8, 16, 32]): List of convolutional kernel depths.</span>
<span class="sd">    </span>
<span class="sd">    k (int or list of ints, 3): Convolutional kernel widths. If an int is</span>
<span class="sd">        passed, it will be multiplied into a list of length `len(c)`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">32</span><span class="p">],</span> <span class="n">k</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="n">k</span> <span class="o">=</span> <span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>
            
        <span class="n">n_nodes</span> <span class="o">=</span> <span class="p">(</span><span class="mi">64</span> <span class="o">-</span> <span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">k</span><span class="p">)</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">k</span><span class="p">)))</span> <span class="o">*</span> <span class="n">c</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

        <span class="nb">super</span><span class="p">(</span><span class="n">ConvNet</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span>  <span class="mi">1</span><span class="p">,</span>  <span class="n">c</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">k</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># 62 x 20</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">c</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">c</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">k</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># 60 x 6 </span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">c</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">k</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># 58 x 1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_nodes</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>  <span class="c1"># 58 x 32 = 1856</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout2d</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softplus</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc3</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">output</span>
</pre></div>
</div>
</div>
</div>
<p>Here we will also define our loss function. A typical loss function for regression is the mean squared error (MSE). However, MSE doesn’t allow for the prediction of uncertainties. Alternative loss functions that allow the prediction of uncertainties include the Laplacian and Gaussian Negative Log-Likelihoods (NLL). Gaussian NLL is analogous to MSE, while Laplacian NLL is analogous to median absolute error, which is less biased by outliers and more accurately predicts values near the edges of the training distribution. For these reasons, we will use the Laplacian NLL, which has the form</p>
<p><span class="math notranslate nohighlight">\(L = \frac{1}{2b} \exp(\frac{-|x - \mu|}{b})\)</span>,</p>
<p>where <span class="math notranslate nohighlight">\(\mu\)</span> is the mean, and <span class="math notranslate nohighlight">\(b\)</span> is related to the variance <span class="math notranslate nohighlight">\(\sigma^2\)</span> by <span class="math notranslate nohighlight">\(\sigma^2 = 2 b^2\)</span>.</p>
<p>The negative log-likelihood is then</p>
<p><span class="math notranslate nohighlight">\(-\log L = \frac{|x - \mu|}{b} + \ln(2b)\)</span>.</p>
<p>You may find that other loss functions work better for your use case. We recommend trying several.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">laplacian_nll</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute Negative Log Likelihood for Laplacian Output Layer. This loss function</span>
<span class="sd">    lets the CNN predict a value with a related uncertainty.</span>

<span class="sd">    Args:</span>
<span class="sd">        y_pred: Nx2k matrix of parameters. Each row parametrizes</span>
<span class="sd">                k Laplacian distributions, each with (mean, std).</span>
<span class="sd">        y_true: Nxk matrix of (data) target values.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">means</span> <span class="o">=</span> <span class="n">y_pred</span><span class="p">[:,</span> <span class="p">:</span><span class="n">k</span><span class="p">]</span>
    <span class="n">sigmas</span> <span class="o">=</span> <span class="n">y_pred</span><span class="p">[:,</span> <span class="n">k</span><span class="p">:]</span>

    <span class="c1"># convert from sigma to b</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">sigmas</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> 

    <span class="c1"># compute NLL</span>
    <span class="n">nll</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">means</span> <span class="o">-</span> <span class="n">y_true</span><span class="p">)</span><span class="o">/</span><span class="n">b</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">b</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">nll</span>

<span class="k">def</span><span class="w"> </span><span class="nf">gaussian_nll</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute Negative Log Likelihood for Gaussian Output Layer. This loss function</span>
<span class="sd">    lets the CNN predict a value with a related uncertainty.</span>

<span class="sd">    Args:</span>
<span class="sd">        y_pred: Nx2k matrix of parameters. Each row parametrizes</span>
<span class="sd">                k Laplacian distributions, each with (mean, std).</span>
<span class="sd">        y_true: Nxk matrix of (data) target values.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">means</span> <span class="o">=</span> <span class="n">y_pred</span><span class="p">[:,</span> <span class="p">:</span><span class="n">k</span><span class="p">]</span>
    <span class="n">sigmas</span> <span class="o">=</span> <span class="n">y_pred</span><span class="p">[:,</span> <span class="n">k</span><span class="p">:]</span> 

    <span class="c1"># compute NLL</span>
    <span class="n">nll</span> <span class="o">=</span> <span class="p">((</span><span class="n">means</span> <span class="o">-</span> <span class="n">y_true</span><span class="p">)</span><span class="o">/</span><span class="n">sigmas</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">*</span><span class="n">sigmas</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">nll</span><span class="o">/</span><span class="mi">2</span>

<span class="c1"># Set the chosen loss function here</span>
<span class="n">loss_function</span> <span class="o">=</span> <span class="n">laplacian_nll</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="define-training-validation-and-evaluation-functions">
<h2>3. Define training, validation, and evaluation functions<a class="headerlink" href="#define-training-validation-and-evaluation-functions" title="Permalink to this heading">#</a></h2>
<p>We train the CNN using the Adam optimizer, which uses adaptive learning rates (LR) to train the network. To vary the LR, we use a plateau scheduler (<code class="docutils literal notranslate"><span class="pre">ReduceLROnPlateau</span></code>), which reduces the LR when the loss plateaus. This enables the CNN parameters to find local minima more easily, rather than take large steps over them.</p>
<p>Finally, we will also use an early stopping criterion. This means that if the validation loss plateaus or increases for a certain number of epochs, training stops early, and the best fit CNN values are saved.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">valid_loader</span><span class="p">,</span> <span class="n">num_epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">early_stopping_patience</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Train the neural network for all desired epochs.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-5</span><span class="p">)</span>
    <span class="c1"># Set learning rate scheduler</span>
    <span class="n">scheduler</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">ReduceLROnPlateau</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">factor</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

    <span class="c1"># Set up training loop</span>
    <span class="n">train_p_loss</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">val_p_loss</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">min_loss</span> <span class="o">=</span> <span class="mi">100</span>
    <span class="n">early_stopping_count</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">best_epoch</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_epochs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="c1"># Compute a single epoch of training</span>
        <span class="n">p_loss</span> <span class="o">=</span> <span class="n">train_epoch</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
        <span class="n">train_p_loss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">p_loss</span><span class="p">)</span>
        <span class="n">p_loss</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">valid_loader</span><span class="p">)</span>
        <span class="n">val_p_loss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">p_loss</span><span class="p">)</span>
        <span class="n">total_loss</span> <span class="o">=</span> <span class="n">p_loss</span>
        <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">total_loss</span><span class="p">)</span>  <span class="c1"># step learning rate scheduler</span>

        <span class="c1"># if new fit is better than the previous best fit, update best fit weights</span>
        <span class="k">if</span> <span class="n">total_loss</span> <span class="o">&lt;</span> <span class="n">min_loss</span><span class="p">:</span>
            <span class="n">min_loss</span> <span class="o">=</span> <span class="n">total_loss</span>
            <span class="n">early_stopping_count</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">best_epoch</span> <span class="o">=</span> <span class="n">epoch</span>
            <span class="n">best_weights</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>
        <span class="c1"># otherwise, if loss is not getting better, count down to stopping criterion</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">early_stopping_count</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Early Stopping Count: </span><span class="si">{</span><span class="n">early_stopping_count</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">early_stopping_count</span> <span class="o">==</span> <span class="n">early_stopping_patience</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Early Stopping. Best Epoch: </span><span class="si">{</span><span class="n">best_epoch</span><span class="si">}</span><span class="s2"> with loss </span><span class="si">{</span><span class="n">min_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
                <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;best_epoch.txt&quot;</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="n">best_epoch</span><span class="p">,</span> <span class="n">file</span><span class="o">=</span><span class="n">f</span><span class="p">)</span>
                <span class="k">break</span>    

    <span class="c1"># save and return the best fit weights</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">best_weights</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;model.pt&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">best_weights</span><span class="p">,</span> <span class="n">train_p_loss</span><span class="p">,</span> <span class="n">val_p_loss</span>


<span class="k">def</span><span class="w"> </span><span class="nf">train_epoch</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Train the network for a single epoch.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>  <span class="c1"># Set the model to training mode</span>
    <span class="n">period_losses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="c1"># iterate over data batches</span>
    <span class="k">for</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
        <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">),</span> <span class="n">target</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>  <span class="c1"># Clear the gradient</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>  <span class="c1"># Make predictions</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>  <span class="c1"># Gradient computation        </span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>  <span class="c1"># Perform a single optimization step</span>
        <span class="n">period_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

        <span class="c1"># print progress every few batches</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">batch_idx</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">))</span> <span class="o">%</span> <span class="mi">500</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Epoch: </span><span class="si">{:3d}</span><span class="s2"> [</span><span class="si">{:5d}</span><span class="s2">/</span><span class="si">{:5d}</span><span class="s2"> (</span><span class="si">{:3.0f}</span><span class="s2">%)] Training Loss: </span><span class="si">{:9.6f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="n">epoch</span><span class="p">,</span> <span class="n">batch_idx</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">),</span>
                <span class="mf">100.</span> <span class="o">*</span> <span class="n">batch_idx</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">),</span> <span class="n">period_losses</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
            
    <span class="c1"># return the mean loss value</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">period_losses</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">evaluate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">),</span> <span class="n">return_predictions</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Evaluate network on validation or test data and compute loss.</span>
<span class="sd">    This is like &quot;train&quot; except the weights are not updated.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>  <span class="c1"># Set the model to inference mode</span>
    <span class="n">test_p_loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">targets</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">preds</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>  <span class="c1"># For the inference step, gradient is not computed</span>
        <span class="k">for</span> <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">test_loader</span><span class="p">:</span>
            <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">),</span> <span class="n">target</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
            <span class="n">targets</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">target</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
            <span class="n">preds</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
            <span class="n">test_p_loss</span> <span class="o">+=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
            
    <span class="n">test_p_loss</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Test loss: </span><span class="si">{</span><span class="n">test_p_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">return_predictions</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">test_p_loss</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">preds</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">targets</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">test_p_loss</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="train-the-cnn-on-smarts-data">
<h2>4. Train the CNN on SMARTS data<a class="headerlink" href="#train-the-cnn-on-smarts-data" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Initialize CNN</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">ConvNet</span><span class="p">(</span><span class="n">c</span><span class="o">=</span><span class="n">filters</span><span class="p">)</span>

<span class="c1"># Train CNN</span>
<span class="n">weights</span><span class="p">,</span> <span class="n">train_p_loss</span><span class="p">,</span> <span class="n">val_p_loss</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">valid_loader</span><span class="p">,</span>
    <span class="n">early_stopping_patience</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">num_epochs</span><span class="o">=</span><span class="n">num_epochs</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   1 [    0/ 8000 (  0%)] Training Loss:  0.575162
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   1 [  500/ 8000 (  6%)] Training Loss:  0.610845
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   1 [ 1000/ 8000 ( 12%)] Training Loss:  0.444789
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   1 [ 1500/ 8000 ( 19%)] Training Loss:  0.438787
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   1 [ 2000/ 8000 ( 25%)] Training Loss:  0.445467
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   1 [ 2500/ 8000 ( 31%)] Training Loss:  0.331284
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   1 [ 3000/ 8000 ( 38%)] Training Loss:  0.381290
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   1 [ 3500/ 8000 ( 44%)] Training Loss:  0.339752
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   1 [ 4000/ 8000 ( 50%)] Training Loss:  0.182749
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   1 [ 4500/ 8000 ( 56%)] Training Loss:  0.371045
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   1 [ 5000/ 8000 ( 62%)] Training Loss:  0.353536
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   1 [ 5500/ 8000 ( 69%)] Training Loss:  0.345336
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   1 [ 6000/ 8000 ( 75%)] Training Loss:  0.232175
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   1 [ 6500/ 8000 ( 81%)] Training Loss:  0.366428
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   1 [ 7000/ 8000 ( 88%)] Training Loss:  0.284384
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   1 [ 7500/ 8000 ( 94%)] Training Loss:  0.492535
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test loss: 0.3045
Epoch:   2 [    0/ 8000 (  0%)] Training Loss:  0.296180
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   2 [  500/ 8000 (  6%)] Training Loss:  0.475287
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   2 [ 1000/ 8000 ( 12%)] Training Loss:  0.272705
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   2 [ 1500/ 8000 ( 19%)] Training Loss:  0.258431
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   2 [ 2000/ 8000 ( 25%)] Training Loss:  0.378992
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   2 [ 2500/ 8000 ( 31%)] Training Loss:  0.208311
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   2 [ 3000/ 8000 ( 38%)] Training Loss:  0.322407
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   2 [ 3500/ 8000 ( 44%)] Training Loss:  0.342891
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   2 [ 4000/ 8000 ( 50%)] Training Loss:  0.210131
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   2 [ 4500/ 8000 ( 56%)] Training Loss:  0.364870
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   2 [ 5000/ 8000 ( 62%)] Training Loss:  0.311264
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   2 [ 5500/ 8000 ( 69%)] Training Loss:  0.309026
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   2 [ 6000/ 8000 ( 75%)] Training Loss:  0.200377
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   2 [ 6500/ 8000 ( 81%)] Training Loss:  0.325533
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   2 [ 7000/ 8000 ( 88%)] Training Loss:  0.286022
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   2 [ 7500/ 8000 ( 94%)] Training Loss:  0.442966
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test loss: 0.2618
Epoch:   3 [    0/ 8000 (  0%)] Training Loss:  0.262717
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   3 [  500/ 8000 (  6%)] Training Loss:  0.406286
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   3 [ 1000/ 8000 ( 12%)] Training Loss:  0.233385
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   3 [ 1500/ 8000 ( 19%)] Training Loss:  0.192313
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   3 [ 2000/ 8000 ( 25%)] Training Loss:  0.341165
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   3 [ 2500/ 8000 ( 31%)] Training Loss:  0.140508
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   3 [ 3000/ 8000 ( 38%)] Training Loss:  0.297368
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   3 [ 3500/ 8000 ( 44%)] Training Loss:  0.227784
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   3 [ 4000/ 8000 ( 50%)] Training Loss:  0.118470
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   3 [ 4500/ 8000 ( 56%)] Training Loss:  0.333037
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   3 [ 5000/ 8000 ( 62%)] Training Loss:  0.290194
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   3 [ 5500/ 8000 ( 69%)] Training Loss:  0.271156
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   3 [ 6000/ 8000 ( 75%)] Training Loss:  0.082075
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   3 [ 6500/ 8000 ( 81%)] Training Loss:  0.270208
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   3 [ 7000/ 8000 ( 88%)] Training Loss:  0.225345
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   3 [ 7500/ 8000 ( 94%)] Training Loss:  0.344451
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test loss: 0.2340
Epoch:   4 [    0/ 8000 (  0%)] Training Loss:  0.256205
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   4 [  500/ 8000 (  6%)] Training Loss:  0.364359
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   4 [ 1000/ 8000 ( 12%)] Training Loss:  0.295996
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   4 [ 1500/ 8000 ( 19%)] Training Loss:  0.120267
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   4 [ 2000/ 8000 ( 25%)] Training Loss:  0.334042
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   4 [ 2500/ 8000 ( 31%)] Training Loss:  0.173124
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   4 [ 3000/ 8000 ( 38%)] Training Loss:  0.248428
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   4 [ 3500/ 8000 ( 44%)] Training Loss:  0.194836
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   4 [ 4000/ 8000 ( 50%)] Training Loss:  0.108231
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   4 [ 4500/ 8000 ( 56%)] Training Loss:  0.266289
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   4 [ 5000/ 8000 ( 62%)] Training Loss:  0.287311
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   4 [ 5500/ 8000 ( 69%)] Training Loss:  0.249780
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   4 [ 6000/ 8000 ( 75%)] Training Loss:  0.114030
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   4 [ 6500/ 8000 ( 81%)] Training Loss:  0.301799
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   4 [ 7000/ 8000 ( 88%)] Training Loss:  0.326320
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   4 [ 7500/ 8000 ( 94%)] Training Loss:  0.388101
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test loss: 0.2333
Epoch:   5 [    0/ 8000 (  0%)] Training Loss:  0.337691
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   5 [  500/ 8000 (  6%)] Training Loss:  0.407707
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   5 [ 1000/ 8000 ( 12%)] Training Loss:  0.257284
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   5 [ 1500/ 8000 ( 19%)] Training Loss:  0.170404
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   5 [ 2000/ 8000 ( 25%)] Training Loss:  0.310470
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   5 [ 2500/ 8000 ( 31%)] Training Loss:  0.141226
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   5 [ 3000/ 8000 ( 38%)] Training Loss:  0.292000
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   5 [ 3500/ 8000 ( 44%)] Training Loss:  0.241041
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   5 [ 4000/ 8000 ( 50%)] Training Loss:  0.113812
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   5 [ 4500/ 8000 ( 56%)] Training Loss:  0.301326
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   5 [ 5000/ 8000 ( 62%)] Training Loss:  0.303455
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   5 [ 5500/ 8000 ( 69%)] Training Loss:  0.275898
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   5 [ 6000/ 8000 ( 75%)] Training Loss:  0.061796
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   5 [ 6500/ 8000 ( 81%)] Training Loss:  0.254562
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   5 [ 7000/ 8000 ( 88%)] Training Loss:  0.298238
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   5 [ 7500/ 8000 ( 94%)] Training Loss:  0.362178
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test loss: 0.2272
Epoch:   6 [    0/ 8000 (  0%)] Training Loss:  0.254310
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   6 [  500/ 8000 (  6%)] Training Loss:  0.322689
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   6 [ 1000/ 8000 ( 12%)] Training Loss:  0.234108
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   6 [ 1500/ 8000 ( 19%)] Training Loss:  0.153513
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   6 [ 2000/ 8000 ( 25%)] Training Loss:  0.338179
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   6 [ 2500/ 8000 ( 31%)] Training Loss:  0.162006
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   6 [ 3000/ 8000 ( 38%)] Training Loss:  0.292955
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   6 [ 3500/ 8000 ( 44%)] Training Loss:  0.220800
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   6 [ 4000/ 8000 ( 50%)] Training Loss:  0.143798
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   6 [ 4500/ 8000 ( 56%)] Training Loss:  0.279670
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   6 [ 5000/ 8000 ( 62%)] Training Loss:  0.265485
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   6 [ 5500/ 8000 ( 69%)] Training Loss:  0.299336
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   6 [ 6000/ 8000 ( 75%)] Training Loss:  0.132134
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   6 [ 6500/ 8000 ( 81%)] Training Loss:  0.273439
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   6 [ 7000/ 8000 ( 88%)] Training Loss:  0.279075
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   6 [ 7500/ 8000 ( 94%)] Training Loss:  0.332744
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test loss: 0.2222
Epoch:   7 [    0/ 8000 (  0%)] Training Loss:  0.250884
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   7 [  500/ 8000 (  6%)] Training Loss:  0.374180
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   7 [ 1000/ 8000 ( 12%)] Training Loss:  0.238376
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   7 [ 1500/ 8000 ( 19%)] Training Loss:  0.135620
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   7 [ 2000/ 8000 ( 25%)] Training Loss:  0.341522
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   7 [ 2500/ 8000 ( 31%)] Training Loss:  0.148944
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   7 [ 3000/ 8000 ( 38%)] Training Loss:  0.313608
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   7 [ 3500/ 8000 ( 44%)] Training Loss:  0.176567
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   7 [ 4000/ 8000 ( 50%)] Training Loss:  0.061224
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   7 [ 4500/ 8000 ( 56%)] Training Loss:  0.252087
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   7 [ 5000/ 8000 ( 62%)] Training Loss:  0.311205
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   7 [ 5500/ 8000 ( 69%)] Training Loss:  0.315710
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   7 [ 6000/ 8000 ( 75%)] Training Loss:  0.145026
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   7 [ 6500/ 8000 ( 81%)] Training Loss:  0.289482
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   7 [ 7000/ 8000 ( 88%)] Training Loss:  0.231719
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   7 [ 7500/ 8000 ( 94%)] Training Loss:  0.327896
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test loss: 0.2167
Epoch:   8 [    0/ 8000 (  0%)] Training Loss:  0.271672
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   8 [  500/ 8000 (  6%)] Training Loss:  0.407888
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   8 [ 1000/ 8000 ( 12%)] Training Loss:  0.212384
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   8 [ 1500/ 8000 ( 19%)] Training Loss:  0.149499
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   8 [ 2000/ 8000 ( 25%)] Training Loss:  0.286266
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   8 [ 2500/ 8000 ( 31%)] Training Loss:  0.172137
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   8 [ 3000/ 8000 ( 38%)] Training Loss:  0.313013
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   8 [ 3500/ 8000 ( 44%)] Training Loss:  0.244127
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   8 [ 4000/ 8000 ( 50%)] Training Loss:  0.124600
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   8 [ 4500/ 8000 ( 56%)] Training Loss:  0.258178
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   8 [ 5000/ 8000 ( 62%)] Training Loss:  0.303822
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   8 [ 5500/ 8000 ( 69%)] Training Loss:  0.312904
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   8 [ 6000/ 8000 ( 75%)] Training Loss:  0.085169
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   8 [ 6500/ 8000 ( 81%)] Training Loss:  0.264361
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   8 [ 7000/ 8000 ( 88%)] Training Loss:  0.249699
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   8 [ 7500/ 8000 ( 94%)] Training Loss:  0.362730
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test loss: 0.2181
Early Stopping Count: 1
Epoch:   9 [    0/ 8000 (  0%)] Training Loss:  0.262929
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   9 [  500/ 8000 (  6%)] Training Loss:  0.368385
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   9 [ 1000/ 8000 ( 12%)] Training Loss:  0.223393
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   9 [ 1500/ 8000 ( 19%)] Training Loss:  0.103982
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   9 [ 2000/ 8000 ( 25%)] Training Loss:  0.336602
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   9 [ 2500/ 8000 ( 31%)] Training Loss:  0.136145
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   9 [ 3000/ 8000 ( 38%)] Training Loss:  0.299505
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   9 [ 3500/ 8000 ( 44%)] Training Loss:  0.237103
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   9 [ 4000/ 8000 ( 50%)] Training Loss:  0.119137
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   9 [ 4500/ 8000 ( 56%)] Training Loss:  0.243878
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   9 [ 5000/ 8000 ( 62%)] Training Loss:  0.300902
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   9 [ 5500/ 8000 ( 69%)] Training Loss:  0.283236
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   9 [ 6000/ 8000 ( 75%)] Training Loss:  0.142143
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   9 [ 6500/ 8000 ( 81%)] Training Loss:  0.270774
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   9 [ 7000/ 8000 ( 88%)] Training Loss:  0.264012
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:   9 [ 7500/ 8000 ( 94%)] Training Loss:  0.333261
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test loss: 0.2070
Epoch:  10 [    0/ 8000 (  0%)] Training Loss:  0.225312
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  10 [  500/ 8000 (  6%)] Training Loss:  0.338756
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  10 [ 1000/ 8000 ( 12%)] Training Loss:  0.206627
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  10 [ 1500/ 8000 ( 19%)] Training Loss:  0.179548
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  10 [ 2000/ 8000 ( 25%)] Training Loss:  0.304030
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  10 [ 2500/ 8000 ( 31%)] Training Loss:  0.128224
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  10 [ 3000/ 8000 ( 38%)] Training Loss:  0.369728
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  10 [ 3500/ 8000 ( 44%)] Training Loss:  0.206604
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  10 [ 4000/ 8000 ( 50%)] Training Loss:  0.132868
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  10 [ 4500/ 8000 ( 56%)] Training Loss:  0.292926
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  10 [ 5000/ 8000 ( 62%)] Training Loss:  0.248278
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  10 [ 5500/ 8000 ( 69%)] Training Loss:  0.305074
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  10 [ 6000/ 8000 ( 75%)] Training Loss:  0.061336
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  10 [ 6500/ 8000 ( 81%)] Training Loss:  0.236473
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  10 [ 7000/ 8000 ( 88%)] Training Loss:  0.264069
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  10 [ 7500/ 8000 ( 94%)] Training Loss:  0.325789
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test loss: 0.2012
Epoch:  11 [    0/ 8000 (  0%)] Training Loss:  0.286728
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  11 [  500/ 8000 (  6%)] Training Loss:  0.338227
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  11 [ 1000/ 8000 ( 12%)] Training Loss:  0.197625
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  11 [ 1500/ 8000 ( 19%)] Training Loss:  0.114818
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  11 [ 2000/ 8000 ( 25%)] Training Loss:  0.258796
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  11 [ 2500/ 8000 ( 31%)] Training Loss:  0.092410
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  11 [ 3000/ 8000 ( 38%)] Training Loss:  0.344620
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  11 [ 3500/ 8000 ( 44%)] Training Loss:  0.236683
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  11 [ 4000/ 8000 ( 50%)] Training Loss:  0.045492
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  11 [ 4500/ 8000 ( 56%)] Training Loss:  0.298449
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  11 [ 5000/ 8000 ( 62%)] Training Loss:  0.324902
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  11 [ 5500/ 8000 ( 69%)] Training Loss:  0.268598
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  11 [ 6000/ 8000 ( 75%)] Training Loss:  0.055375
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  11 [ 6500/ 8000 ( 81%)] Training Loss:  0.257181
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  11 [ 7000/ 8000 ( 88%)] Training Loss:  0.237169
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  11 [ 7500/ 8000 ( 94%)] Training Loss:  0.282529
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test loss: 0.1945
Epoch:  12 [    0/ 8000 (  0%)] Training Loss:  0.241708
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  12 [  500/ 8000 (  6%)] Training Loss:  0.373011
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  12 [ 1000/ 8000 ( 12%)] Training Loss:  0.153525
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  12 [ 1500/ 8000 ( 19%)] Training Loss:  0.079620
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  12 [ 2000/ 8000 ( 25%)] Training Loss:  0.313065
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  12 [ 2500/ 8000 ( 31%)] Training Loss:  0.077472
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  12 [ 3000/ 8000 ( 38%)] Training Loss:  0.322882
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  12 [ 3500/ 8000 ( 44%)] Training Loss:  0.211778
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  12 [ 4000/ 8000 ( 50%)] Training Loss:  0.038527
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  12 [ 4500/ 8000 ( 56%)] Training Loss:  0.264031
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  12 [ 5000/ 8000 ( 62%)] Training Loss:  0.299187
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  12 [ 5500/ 8000 ( 69%)] Training Loss:  0.315940
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  12 [ 6000/ 8000 ( 75%)] Training Loss:  0.038248
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  12 [ 6500/ 8000 ( 81%)] Training Loss:  0.242998
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  12 [ 7000/ 8000 ( 88%)] Training Loss:  0.244771
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  12 [ 7500/ 8000 ( 94%)] Training Loss:  0.269640
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test loss: 0.1830
Epoch:  13 [    0/ 8000 (  0%)] Training Loss:  0.186747
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  13 [  500/ 8000 (  6%)] Training Loss:  0.328821
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  13 [ 1000/ 8000 ( 12%)] Training Loss:  0.153123
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  13 [ 1500/ 8000 ( 19%)] Training Loss:  0.108869
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  13 [ 2000/ 8000 ( 25%)] Training Loss:  0.257631
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  13 [ 2500/ 8000 ( 31%)] Training Loss:  0.141544
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  13 [ 3000/ 8000 ( 38%)] Training Loss:  0.260475
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  13 [ 3500/ 8000 ( 44%)] Training Loss:  0.171047
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  13 [ 4000/ 8000 ( 50%)] Training Loss:  0.015325
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  13 [ 4500/ 8000 ( 56%)] Training Loss:  0.340913
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  13 [ 5000/ 8000 ( 62%)] Training Loss:  0.221867
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  13 [ 5500/ 8000 ( 69%)] Training Loss:  0.302691
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  13 [ 6000/ 8000 ( 75%)] Training Loss:  0.039959
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  13 [ 6500/ 8000 ( 81%)] Training Loss:  0.223356
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  13 [ 7000/ 8000 ( 88%)] Training Loss:  0.178487
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  13 [ 7500/ 8000 ( 94%)] Training Loss:  0.207351
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test loss: 0.1710
Epoch:  14 [    0/ 8000 (  0%)] Training Loss:  0.184514
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  14 [  500/ 8000 (  6%)] Training Loss:  0.320723
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  14 [ 1000/ 8000 ( 12%)] Training Loss:  0.145266
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  14 [ 1500/ 8000 ( 19%)] Training Loss:  0.098035
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  14 [ 2000/ 8000 ( 25%)] Training Loss:  0.219390
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  14 [ 2500/ 8000 ( 31%)] Training Loss:  0.043216
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  14 [ 3000/ 8000 ( 38%)] Training Loss:  0.258917
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  14 [ 3500/ 8000 ( 44%)] Training Loss:  0.177623
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  14 [ 4000/ 8000 ( 50%)] Training Loss:  0.018683
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  14 [ 4500/ 8000 ( 56%)] Training Loss:  0.321617
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  14 [ 5000/ 8000 ( 62%)] Training Loss:  0.298061
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  14 [ 5500/ 8000 ( 69%)] Training Loss:  0.221937
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  14 [ 6000/ 8000 ( 75%)] Training Loss:  0.022262
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  14 [ 6500/ 8000 ( 81%)] Training Loss:  0.252438
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  14 [ 7000/ 8000 ( 88%)] Training Loss:  0.232324
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  14 [ 7500/ 8000 ( 94%)] Training Loss:  0.227102
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test loss: 0.1636
Epoch:  15 [    0/ 8000 (  0%)] Training Loss:  0.220585
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  15 [  500/ 8000 (  6%)] Training Loss:  0.308488
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  15 [ 1000/ 8000 ( 12%)] Training Loss:  0.170905
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  15 [ 1500/ 8000 ( 19%)] Training Loss:  0.106915
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  15 [ 2000/ 8000 ( 25%)] Training Loss:  0.224367
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  15 [ 2500/ 8000 ( 31%)] Training Loss:  0.120642
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  15 [ 3000/ 8000 ( 38%)] Training Loss:  0.250475
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  15 [ 3500/ 8000 ( 44%)] Training Loss:  0.170506
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  15 [ 4000/ 8000 ( 50%)] Training Loss:  0.023384
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  15 [ 4500/ 8000 ( 56%)] Training Loss:  0.263970
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  15 [ 5000/ 8000 ( 62%)] Training Loss:  0.274798
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  15 [ 5500/ 8000 ( 69%)] Training Loss:  0.236568
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  15 [ 6000/ 8000 ( 75%)] Training Loss:  0.003615
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  15 [ 6500/ 8000 ( 81%)] Training Loss:  0.208258
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  15 [ 7000/ 8000 ( 88%)] Training Loss:  0.232558
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  15 [ 7500/ 8000 ( 94%)] Training Loss:  0.232522
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test loss: 0.1546
Epoch:  16 [    0/ 8000 (  0%)] Training Loss:  0.267334
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  16 [  500/ 8000 (  6%)] Training Loss:  0.313345
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  16 [ 1000/ 8000 ( 12%)] Training Loss:  0.155407
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  16 [ 1500/ 8000 ( 19%)] Training Loss:  0.088002
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  16 [ 2000/ 8000 ( 25%)] Training Loss:  0.168831
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  16 [ 2500/ 8000 ( 31%)] Training Loss:  0.074557
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  16 [ 3000/ 8000 ( 38%)] Training Loss:  0.264558
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  16 [ 3500/ 8000 ( 44%)] Training Loss:  0.135820
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  16 [ 4000/ 8000 ( 50%)] Training Loss:  0.029167
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  16 [ 4500/ 8000 ( 56%)] Training Loss:  0.288098
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  16 [ 5000/ 8000 ( 62%)] Training Loss:  0.258994
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  16 [ 5500/ 8000 ( 69%)] Training Loss:  0.280464
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  16 [ 6000/ 8000 ( 75%)] Training Loss:  0.068615
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  16 [ 6500/ 8000 ( 81%)] Training Loss:  0.211652
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  16 [ 7000/ 8000 ( 88%)] Training Loss:  0.208525
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  16 [ 7500/ 8000 ( 94%)] Training Loss:  0.274456
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test loss: 0.1454
Epoch:  17 [    0/ 8000 (  0%)] Training Loss:  0.252409
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  17 [  500/ 8000 (  6%)] Training Loss:  0.346439
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  17 [ 1000/ 8000 ( 12%)] Training Loss:  0.082718
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  17 [ 1500/ 8000 ( 19%)] Training Loss:  0.016846
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  17 [ 2000/ 8000 ( 25%)] Training Loss:  0.223700
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  17 [ 2500/ 8000 ( 31%)] Training Loss:  0.058964
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  17 [ 3000/ 8000 ( 38%)] Training Loss:  0.246388
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  17 [ 3500/ 8000 ( 44%)] Training Loss:  0.185188
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  17 [ 4000/ 8000 ( 50%)] Training Loss:  0.003403
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  17 [ 4500/ 8000 ( 56%)] Training Loss:  0.316264
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  17 [ 5000/ 8000 ( 62%)] Training Loss:  0.316291
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  17 [ 5500/ 8000 ( 69%)] Training Loss:  0.273281
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  17 [ 6000/ 8000 ( 75%)] Training Loss: -0.008495
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  17 [ 6500/ 8000 ( 81%)] Training Loss:  0.204137
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  17 [ 7000/ 8000 ( 88%)] Training Loss:  0.183708
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  17 [ 7500/ 8000 ( 94%)] Training Loss:  0.204157
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test loss: 0.1356
Epoch:  18 [    0/ 8000 (  0%)] Training Loss:  0.214294
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  18 [  500/ 8000 (  6%)] Training Loss:  0.264618
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  18 [ 1000/ 8000 ( 12%)] Training Loss:  0.118414
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  18 [ 1500/ 8000 ( 19%)] Training Loss:  0.028611
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  18 [ 2000/ 8000 ( 25%)] Training Loss:  0.226510
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  18 [ 2500/ 8000 ( 31%)] Training Loss:  0.065674
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  18 [ 3000/ 8000 ( 38%)] Training Loss:  0.198359
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  18 [ 3500/ 8000 ( 44%)] Training Loss:  0.114771
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  18 [ 4000/ 8000 ( 50%)] Training Loss:  0.000107
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  18 [ 4500/ 8000 ( 56%)] Training Loss:  0.331509
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  18 [ 5000/ 8000 ( 62%)] Training Loss:  0.289340
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  18 [ 5500/ 8000 ( 69%)] Training Loss:  0.275291
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  18 [ 6000/ 8000 ( 75%)] Training Loss: -0.024939
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  18 [ 6500/ 8000 ( 81%)] Training Loss:  0.160678
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  18 [ 7000/ 8000 ( 88%)] Training Loss:  0.228051
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  18 [ 7500/ 8000 ( 94%)] Training Loss:  0.181976
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test loss: 0.1210
Epoch:  19 [    0/ 8000 (  0%)] Training Loss:  0.347059
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  19 [  500/ 8000 (  6%)] Training Loss:  0.312782
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  19 [ 1000/ 8000 ( 12%)] Training Loss:  0.053068
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  19 [ 1500/ 8000 ( 19%)] Training Loss:  0.050921
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  19 [ 2000/ 8000 ( 25%)] Training Loss:  0.097798
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  19 [ 2500/ 8000 ( 31%)] Training Loss:  0.116656
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  19 [ 3000/ 8000 ( 38%)] Training Loss:  0.170591
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  19 [ 3500/ 8000 ( 44%)] Training Loss:  0.171495
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  19 [ 4000/ 8000 ( 50%)] Training Loss: -0.028286
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  19 [ 4500/ 8000 ( 56%)] Training Loss:  0.268572
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  19 [ 5000/ 8000 ( 62%)] Training Loss:  0.315440
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  19 [ 5500/ 8000 ( 69%)] Training Loss:  0.179195
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  19 [ 6000/ 8000 ( 75%)] Training Loss: -0.035189
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  19 [ 6500/ 8000 ( 81%)] Training Loss:  0.169484
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  19 [ 7000/ 8000 ( 88%)] Training Loss:  0.163280
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  19 [ 7500/ 8000 ( 94%)] Training Loss:  0.118794
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test loss: 0.1101
Epoch:  20 [    0/ 8000 (  0%)] Training Loss:  0.242851
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  20 [  500/ 8000 (  6%)] Training Loss:  0.256537
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  20 [ 1000/ 8000 ( 12%)] Training Loss:  0.111477
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  20 [ 1500/ 8000 ( 19%)] Training Loss:  0.021284
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  20 [ 2000/ 8000 ( 25%)] Training Loss:  0.116904
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  20 [ 2500/ 8000 ( 31%)] Training Loss:  0.081162
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  20 [ 3000/ 8000 ( 38%)] Training Loss:  0.311807
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  20 [ 3500/ 8000 ( 44%)] Training Loss:  0.119477
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  20 [ 4000/ 8000 ( 50%)] Training Loss: -0.040711
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  20 [ 4500/ 8000 ( 56%)] Training Loss:  0.269962
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  20 [ 5000/ 8000 ( 62%)] Training Loss:  0.333823
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  20 [ 5500/ 8000 ( 69%)] Training Loss:  0.193534
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  20 [ 6000/ 8000 ( 75%)] Training Loss: -0.118823
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  20 [ 6500/ 8000 ( 81%)] Training Loss:  0.208642
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  20 [ 7000/ 8000 ( 88%)] Training Loss:  0.161853
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch:  20 [ 7500/ 8000 ( 94%)] Training Loss:  0.138950
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test loss: 0.1066
</pre></div>
</div>
</div>
</div>
<p>Now that the CNN is trained, we should take a look at the “learning curves,” or the loss over time.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">train_p_loss</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Training Loss&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">val_p_loss</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Validation Loss&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Epoch&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Loss&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/cdfc5058c414c8b2958ec2157f18151a824393435c0433fb3aff5ccad8f3cf47.png" src="../../../_images/cdfc5058c414c8b2958ec2157f18151a824393435c0433fb3aff5ccad8f3cf47.png" />
</div>
</div>
<p>For this exercise, we only trained on a small subset of the training data, and for a limited number of training epochs. This means that the CNN hasn’t yet reached a plateau, and it’s not fully trained. You will see better performance by training for more epochs (until the loss values plateau), which you can configure back in <span class="xref myst">Section 0</span> by changing <code class="docutils literal notranslate"><span class="pre">num_epochs</span></code>. You can also train on a larger piece of the training data by configuring <code class="docutils literal notranslate"><span class="pre">max_n</span></code> in the same cell.</p>
</section>
<section id="test-the-cnn-performance">
<h2>5. Test the CNN performance<a class="headerlink" href="#test-the-cnn-performance" title="Permalink to this heading">#</a></h2>
<p>Now we use the trained CNN to predict stellar rotation periods from a held-out test set, and compare the predictions to the true values.</p>
<p>Since we’re only training over a small fraction of the training set in this tutorial, we don’t expect the predictions to match the true values. You will see better performance by training on a larger piece (or all) of the training set, or training for more epochs, by configuring <code class="docutils literal notranslate"><span class="pre">max_n</span></code> or <code class="docutils literal notranslate"><span class="pre">num_epochs</span></code> back in <span class="xref myst">Section 0</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># evaluate CNN to infer rotation periods</span>
<span class="n">test_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
<span class="n">test_loss</span><span class="p">,</span> <span class="n">preds</span><span class="p">,</span> <span class="n">trues</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_predictions</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test loss: 0.0655
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># compare the CNN predictions to the true values</span>
<span class="o">%</span><span class="k">matplotlib</span> inline

<span class="n">true_periods</span> <span class="o">=</span> <span class="n">trues</span><span class="o">*</span><span class="n">test_dataset</span><span class="o">.</span><span class="n">pmax</span>
<span class="n">pred_periods</span> <span class="o">=</span> <span class="n">preds</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">test_dataset</span><span class="o">.</span><span class="n">pmax</span>
<span class="n">pred_sigma</span> <span class="o">=</span> <span class="n">preds</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">test_dataset</span><span class="o">.</span><span class="n">pmax</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">true_periods</span><span class="p">,</span> <span class="n">pred_periods</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">pred_sigma</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">180</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">180</span><span class="p">],</span> <span class="s2">&quot;k&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;True Period (days)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Predicted Period (days)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;Predicted Period Uncertainty (days)&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/a92c3b05d659277e4ecc224d203a0a49e25912a01cf597b7829d9c48d065efcf.png" src="../../../_images/a92c3b05d659277e4ecc224d203a0a49e25912a01cf597b7829d9c48d065efcf.png" />
</div>
</div>
<p>Most of the data are predicted to have the median period of 90 days, which is the best guess when the CNN doesn’t know better. We also predicted the uncertainty in the period, so let’s see what that looks like.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sigmas</span> <span class="o">=</span> <span class="n">preds</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">test_dataset</span><span class="o">.</span><span class="n">pmax</span>
<span class="n">frac</span> <span class="o">=</span> <span class="n">sigmas</span><span class="o">/</span><span class="n">pred_periods</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">sigmas</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Predicted Period Uncertainty (days)&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">frac</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Fractional Period Uncertainty&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/494dcf06b841fcac5cb104b67ff4e7eeeb4335bc14b019dc258f5e457f852353.png" src="../../../_images/494dcf06b841fcac5cb104b67ff4e7eeeb4335bc14b019dc258f5e457f852353.png" />
<img alt="../../../_images/b9abd8db42edfa40c4d3a589b0568b90cacea738482247d8a46d7d4c91f846cf.png" src="../../../_images/b9abd8db42edfa40c4d3a589b0568b90cacea738482247d8a46d7d4c91f846cf.png" />
</div>
</div>
<p>We can start to see a dip forming at sigma/period ~ 0.5 in the second plot (this dip will become more pronounced for longer training runs), so let’s use that to filter the results, weeding out “bad” predictions.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">true_filtered</span> <span class="o">=</span> <span class="n">true_periods</span><span class="p">[</span><span class="n">frac</span> <span class="o">&lt;</span> <span class="mf">0.5</span><span class="p">]</span>
<span class="n">pred_filtered</span> <span class="o">=</span> <span class="n">pred_periods</span><span class="p">[</span><span class="n">frac</span> <span class="o">&lt;</span> <span class="mf">0.5</span><span class="p">]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">true_filtered</span><span class="p">,</span> <span class="n">pred_filtered</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">180</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">180</span><span class="p">],</span> <span class="s2">&quot;k&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;True Period (days)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Predicted Period (days)&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/2175c4a11885e073ebcecb406451c1fe912164d5d1a08e41dfb3e23b3c9f46e3.png" src="../../../_images/2175c4a11885e073ebcecb406451c1fe912164d5d1a08e41dfb3e23b3c9f46e3.png" />
</div>
</div>
<p>With the “bad” predictions filtered out, the predictions look much better, even after only 20 epochs. Remember that the uncertainty is predicted from the quality of the data, so this kind of cut can be applied to predictions on real data as well.</p>
<p>While our loss function can serve as a metric of accuracy, we might also be interested in more classical accuracy metrics to measure the performance of the CNN. As an example, let’s take a look at the root-mean-squared (RMS) error.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">rms_error</span><span class="p">(</span><span class="n">true</span><span class="p">,</span> <span class="n">pred</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">true</span> <span class="o">-</span> <span class="n">pred</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unfiltered prediction count: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">pred_periods</span><span class="p">)</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
      <span class="sa">f</span><span class="s2">&quot;RMS error: </span><span class="si">{</span><span class="n">rms_error</span><span class="p">(</span><span class="n">true_periods</span><span class="p">,</span><span class="w"> </span><span class="n">pred_periods</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> days</span><span class="se">\n\n</span><span class="s2">&quot;</span>
      <span class="sa">f</span><span class="s2">&quot;Filtered prediction count:   </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">pred_filtered</span><span class="p">)</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
      <span class="sa">f</span><span class="s2">&quot;RMS error: </span><span class="si">{</span><span class="n">rms_error</span><span class="p">(</span><span class="n">true_filtered</span><span class="p">,</span><span class="w"> </span><span class="n">pred_filtered</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> days.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Unfiltered prediction count: 1000
RMS error: 45.67 days

Filtered prediction count:   223
RMS error: 29.18 days.
</pre></div>
</div>
</div>
</div>
<p>When the predictions are filtered, we retain only a fraction of the test data, but the accuracy improves significantly. Note that</p>
<ul class="simple">
<li><p>Filtering by predicted uncertainty improves the accuracy. This implies that the predicted uncertainty is a useful estimator of the true credibility of CNN predictions.</p></li>
<li><p>While only a fraction of the test set is left after filtering, remember that we trained for only 20 epochs, and on a subset of the training data. Doing a full run will improve both the accuracy of predictions <em>and</em> the number of “good” predictions.</p></li>
</ul>
</section>
<section id="summary">
<h2>Summary<a class="headerlink" href="#summary" title="Permalink to this heading">#</a></h2>
<p>CNNs are useful machine learning models that can leverage spatially correlated information in images and image-like data. CNNs trained on simulated light curve wavelet transforms make reasonable predictions of the rotation periods of TESS stars despite the complicated orbit-related systematics present in the light curves.</p>
<p>In this tutorial, we</p>
<ol class="arabic simple">
<li><p>downloaded and preprocessed training data from MAST,</p></li>
<li><p>built a CNN using <code class="docutils literal notranslate"><span class="pre">pytorch</span></code>,</p></li>
<li><p>defined training, validation, and evaluation functions,</p></li>
<li><p>trained the CNN, and</p></li>
<li><p>analyzed the CNN performance on held-out test data.</p></li>
</ol>
<p>We explored various machine learning and astrophysics concepts, including</p>
<ul class="simple">
<li><p>stellar rotation with TESS light curves,</p></li>
<li><p>continuous wavelet transforms, and</p></li>
<li><p>specialized loss functions to predict values with uncertainty.</p></li>
</ul>
</section>
<section id="next-steps">
<h2>Next Steps<a class="headerlink" href="#next-steps" title="Permalink to this heading">#</a></h2>
<p>Now that we’ve run the base case, try the following exercises:</p>
<ul class="simple">
<li><p>train on a larger fraction of the training data by increasing <code class="docutils literal notranslate"><span class="pre">max_n</span></code>,</p></li>
<li><p>train for more epochs by increasing <code class="docutils literal notranslate"><span class="pre">num_epochs</span></code>,</p></li>
<li><p>use different train/validation/test ratios by modifying <code class="docutils literal notranslate"><span class="pre">split</span></code>,</p></li>
<li><p>use larger convolution filter depths by changing <code class="docutils literal notranslate"><span class="pre">filters</span></code>,</p></li>
<li><p>use Gaussian NLL loss to train the CNN.</p></li>
</ul>
<p>See how any of these choices might affect the CNN performance.</p>
</section>
<section id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://ui.adsabs.harvard.edu/abs/2022ApJ...927..219C/abstract"><em>Recovery of TESS Stellar Rotation Periods Using Deep Learning</em> (Claytor et al. 2022)</a></p></li>
<li><p><a class="reference external" href="https://ui.adsabs.harvard.edu/abs/2024ApJ...962...47C/abstract"><em>TESS Stellar Rotation up to 80 Days in the Southern Continuous Viewing Zone</em> (Claytor et al. 2024)</a></p></li>
<li><p><a class="reference external" href="https://ui.adsabs.harvard.edu/abs/1998BAMS...79...61T/abstract"><em>A Practical Guide to Wavelet Analysis</em> (Torrence &amp; Compo 1998)</a></p></li>
<li><p><a class="reference external" href="https://archive.stsci.edu/hlsp/smarts">Stellar Magnetism, Activity, and Rotation with Time Series (SMARTS)</a></p></li>
</ul>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./notebooks/hello-universe/Estimating_TESS_rotation_periods_with_CNNs"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction">Introduction</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#goals">Goals</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#runtime">Runtime</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#installs-and-imports">Installs and Imports</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#configure-training-run">0. Configure training run</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#prepare-training-data">1. Prepare training data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#build-the-cnn">2. Build the CNN</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#define-training-validation-and-evaluation-functions">3. Define training, validation, and evaluation functions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#train-the-cnn-on-smarts-data">4. Train the CNN on SMARTS data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#test-the-cnn-performance">5. Test the CNN performance</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#summary">Summary</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#next-steps">Next Steps</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#references">References</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By STScI Notebook Dev
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2022-2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>